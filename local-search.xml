<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>TSCIL论文笔记</title>
    <link href="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="阅读论文">〇、阅读论文</h1><ol type="1"><li><a href="https://arxiv.org/abs/1904.07734">增量学习的三种场景及方法：Three scenarios for continual learning</a></li><li><a href="https://arxiv.org/abs/2112.08654">预训练模型图像类增量学习：Learning to Prompt for Continual Learning</a></li><li><a href="https://arxiv.org/abs/2402.12035">时间序列类增量学习的基准：Class-incremental Learning for Time Series:Benchmark and Evaluation</a></li><li><a href="https://arxiv.org/abs/2204.04799">DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</a></li><li><a href="https://arxiv.org/abs/2402.03885">时间序列大模型：MOMENT: A Family of Open Time-series Foundation Models</a></li><li><a href="https://arxiv.org/abs/2403.20317">Convolutional Prompting meets Language Models for Continual Learning</a></li></ol><h1 id="一相关工作">一、相关工作</h1><h2 id="增量学习的三种场景及方法">1. 增量学习的三种场景及方法</h2><h3 id="实验方法">1.1 实验方法</h3><ol type="1"><li>正则化（SI、EWC）</li><li>重放（Replay）<ol type="1"><li>用之前模型对当前任务的Input进行标注生成伪数据（LwF）</li><li>生成新数据（DGR、DGR+distill）</li><li>原始数据重现（可能会有隐私或内存问题）</li></ol></li><li>Exemplars（特征提取+最近类均值+重放：iCaRL）</li></ol><h3 id="实验结果">1.2 实验结果</h3><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MNIST结果.png" alt="实验结果对比：正则化的效果普遍不太行"><figcaption aria-hidden="true">实验结果对比：正则化的效果普遍不太行</figcaption></figure><h2 id="预训练模型图像类增量学习">2. 预训练模型图像类增量学习</h2><h3 id="实验方法-1">2.1 实验方法</h3><ol type="1"><li>设Input为<span class="math inline">\(x\)</span>，通过<span class="math inline">\(q(x)\)</span>进行映射</li><li>计算<span class="math inline">\(q(x)\)</span>与Key的余弦相似度并选择TopN（同一Prompt被选择的次数越多，下次被选择的概率越小）</li><li>将TopN向量，以及进入Embedding层的Input拼接，并放入预训练模型</li></ol><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/L2P.png" alt="L2P"><figcaption aria-hidden="true">L2P</figcaption></figure><h4 id="vit">2.1.1 ViT</h4><p>在细读论文时需要一些ViT的知识，于是找到了这篇博客：<a href="https://blog.csdn.net/MengYa_Dream/article/details/126600748">ViT的cls token作用</a></p><ol type="1"><li>论文中假设输入的2D图像<span class="math inline">\(x \in \mathbb{R}^{H \times W \times C}\)</span>中<span class="math inline">\(H\)</span>，<span class="math inline">\(W\)</span>，<span class="math inline">\(C\)</span>分别代表高度，宽度和通道数</li><li><span class="math inline">\(f=f_r \circ f_e\)</span>是一个复合函数，指的是将输入embedding后送入自注意力层的结果</li><li>ViT中，图像需要切分为若干patch；在这里flattened 2D patches <span class="math inline">\(x_p \in \mathbb{R}^{L \times (S^2 \cdot C)}\)</span>，其中<span class="math inline">\(L\)</span>为patches个数，<span class="math inline">\(S\)</span>为patch size</li><li>为了简化表示，<span class="math inline">\(x_p\)</span>的第一个token被当做是<code>[class token]</code></li><li>embedding layer的作用<span class="math inline">\(f_e:\mathbb{R}^{L \times (S^2 \cdot C)} \rightarrow \mathbb{R}^{L \times D}\)</span>，其中<span class="math inline">\(D\)</span>是嵌入维度</li><li>一个Prompt可以看作是$P_e^{L_p D} <span class="math inline">\(，其中\)</span>L_p$是Prompt的长度</li><li>将Prompt和Input拼接起来可以得到<span class="math inline">\(x_p=[P_e;x_e]\)</span></li><li>送入预训练模型后，即<span class="math inline">\(f=f_r(x_p)\)</span></li></ol><h4 id="prompt-pool">2.1.2 Prompt Pool</h4><p>为什么要采用Pool的原因有三：</p><ol type="1"><li>在推理的时候task identity是不得而知的，因此为每个task设置一个prompt是不可行的</li><li>即使推理时上述信息可以得知，那么task-independent prompt可能阻止了相似任务间的信息共享</li><li>如果只用一个prompt，则会造成灾难性遗忘</li></ol><p>于是定义Prompt集合：<span class="math inline">\(P = \{P_1, P_2, \cdots , P_M \}\)</span>，则ViT的输入为：<span class="math inline">\(x_p = [P_{s_1} ; \cdots ; P_{s_N} ; x_e], 1 ≤ N ≤ M\)</span></p><p>Prompt Pool中其实是Key-Value pair：<span class="math inline">\(\{(k_1, P_1), (k_2, P_2), \cdots , (k_M , P_M )\},k_i \in \mathbb{R}^{D_k}\)</span></p><div class="note note-info">            <p>根据论文来看，M为所有Prompt 的数量，是一个可以定义的参数</p>          </div><h4 id="prompt-query">2.1.3 Prompt Query</h4><ol type="1"><li>Query应仅跟输入实例有关，并且没有可学习的参数；定义Query Function：<span class="math inline">\(q : \mathbb{R}^{H\times W \times C} → \mathbb{R}^{D_k}\)</span></li><li>作者用了ViT作为feature extractor：<span class="math inline">\(q(x) = f (x)[0,:]\)</span>，其实就是<code>[class token]</code>对应的向量<ul><li>同时，作者指出用ConvNet也是可行的</li></ul></li><li>定义相似度计算函数<span class="math inline">\(\gamma : \mathbb{R}^{D_k} \times \mathbb{R}^{D_k} \rightarrow \mathbb{R}\)</span>，作者发现余弦相似度就很好</li><li>问题简化为$</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>类增量学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BIGAI1-基于Langchain构建用于数据生成Agent</title>
    <link href="/2024/08/06/%E5%9F%BA%E4%BA%8ELangchain%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90Agent/"/>
    <url>/2024/08/06/%E5%9F%BA%E4%BA%8ELangchain%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90Agent/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><p>类似的文章已经在<a href="https://blog.csdn.net/sersama/article/details/139179060?spm=1001.2014.3001.5502">CSDN</a>发布过了，在这里进行简单总结。</p><h1 id="背景">背景</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>实习</tag>
      
      <tag>BIGAI</tag>
      
      <tag>数据生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>百度-基于大模型的广告检索</title>
    <link href="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/"/>
    <url>/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="数据分析以及初赛方法">数据分析以及初赛方法</h1><h2 id="query落地页核心词长度分布">Query、落地页、核心词长度分布</h2><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/query.png" alt="query"><figcaption aria-hidden="true">query</figcaption></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/lp.png" alt="lp"><figcaption aria-hidden="true">lp</figcaption></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/ct.png" alt="ct"><figcaption aria-hidden="true">ct</figcaption></figure><h2 id="广告id分布">广告ID分布</h2><p>在发现Query中的ID远少于广告ID数量后，我想统计ID的分布。最开始采用柱状图，但由于数据量过大，最后绘制出的图像不直观。因此，我向Kimi问到了一种估计分布密度的方法<a href="https://blog.csdn.net/weixin_39910711/article/details/107307509">KDE</a>，这是一种非参数估计方法，相对于参数估计（如：最大似然估计）不需要对数据的分布有先验的认识：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> gaussian_kde<br><br>json file =<span class="hljs-string">&#x27;/home/zym/桌面/FEIJIANG/Doc/Doc_train_ultra.json&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(json file,<span class="hljs-string">&#x27;r&#x27;</span>,encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<span class="hljs-keyword">as</span> file:<br>    js =[json.loads(line)<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> file]<br>    <br>tgt_values=[ _[<span class="hljs-string">&#x27;tgt&#x27;</span>]<span class="hljs-keyword">for</span> <span class="hljs-keyword">in</span> js]<br>tgt_array=np.array(tgt_values,dtype=np.float64)<br><br><span class="hljs-comment"># 将列表转换为NumPy数组</span><br>tgt_array = np.array(tgt_values, dtype=np.float64)<br><br><span class="hljs-comment"># 计算核密度估计，使用高斯核</span><br>kde = gaussian_kde(tgt_array)<br><br><span class="hljs-comment"># 绘制平滑的曲线</span><br>x = np.linspace(np.<span class="hljs-built_in">min</span>(tgt_array), np.<span class="hljs-built_in">max</span>(tgt_array), <span class="hljs-number">1000</span>)<br>y = kde(x)<br></code></pre></td></tr></table></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/ID分布.png" alt="初赛数据的广告ID分布"><figcaption aria-hidden="true">初赛数据的广告ID分布</figcaption></figure><h2 id="训练过程">训练过程</h2><p>在论文中</p><h1 id="baseline">Baseline</h1><p>数据集中有88wDoc，因为论文中提到直接索引效果较好，因此取落地页连续的短语作为Doc；特别地，观察到Doc长度分布不均，因此在生成Doc时设定为长度越长、采样次数越多。最终得到880wDoc，在第一阶段进行索引学习时4000steps已趋于收敛，遂暂停。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/简单Doc.png" alt="简单构建Doc"><figcaption aria-hidden="true">简单构建Doc</figcaption></figure><p>对于Query，按Click进行增强，从500w得到1200w数据。在上一步得到的权重上训练，效果还可以。</p><h1 id="尝试一semantic-docid">尝试一：Semantic DocID</h1><p>官方所给的数据集中ID是没有规律的，不同的广告内容ID可能邻近，相似的广告ID可能很远，因此这对生成式模型而言，像是在做一个“多分类”的任务。在这篇<a href="https://arxiv.org/abs/2309.13335">Model-enhanced Vector Index</a>论文中提到利用Residual Quantization进行层次聚类效果可能会好，于是考虑用模型对广告内容进行Embedding，但因为本地没有显卡用，并且在AIstudio又不能用Pytorch，因此采用<a href="https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers/ERNIE/contents.html">Ernie-3.0-mini</a>。</p><h2 id="q1embedding文件太大">Q1：Embedding文件太大</h2><p>即使采用mini，在对约29000个句子（3%）进行Embedding之后，我的json文件就已经达到了220MB</p><p><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/mini.png"></p><p>文件存储格式如下</p><p><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/json.png"></p><h2 id="q2内存过大">Q2：内存过大</h2><p>因为词袋方法耗时更长，占用内存更大，后来又再次尝试使用Embedding。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;/home/aistudio/embed.json&quot;</span>,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    data=[json.loads(line)<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f]<br></code></pre></td></tr></table></figure><p>居然在读取的时候内存就满了。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/内存.png" alt="内存满了"><figcaption aria-hidden="true">内存满了</figcaption></figure><h1 id="尝试二词袋">尝试二：词袋</h1><p>这里使用Paddle里的Taskflow进行分词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./embed.json&quot;</span>,<span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(res)+<span class="hljs-number">1</span>)):<br>        seg = Taskflow(<span class="hljs-string">&quot;word segmentation&quot;</span>)temp = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x:x!=,<span class="hljs-string">&#x27;,seg(res[str(i)])))</span><br><span class="hljs-string">        # 使用counter计算每个分词出现的次数</span><br><span class="hljs-string">        word count= counter(temp)</span><br><span class="hljs-string">        #按照出现次数进行升序排序</span><br><span class="hljs-string">        sorted word count = dict(sorted(word count.items(), key=lambda item: item[1]))</span><br><span class="hljs-string">        json.dump(&#123;&quot;tgt&quot;:i,&quot;bow&quot;: sorted word count&#125;,f,ensure ascii=False)</span><br></code></pre></td></tr></table></figure><p>最终分词结果文件很大，没有进一步处理。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/分词.png" alt="分词结果"><figcaption aria-hidden="true">分词结果</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>百度</tag>
      
      <tag>大模型</tag>
      
      <tag>搜广推</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BIGAI2—微调Qwen-7B生成1-Hop描述</title>
    <link href="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/"/>
    <url>/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="背景">背景</h1><p>在生成QA时，我们希望生成的数据具有<mark>一定的复杂度</mark>，并且具有<mark>生活化</mark>的特点。</p><p>最基本的一个想法是：当我们需要某个子图（Region Graph）中的物体信息，便直接从已有信息Info中查找，并送入GPT生成QA；然而，基于这种方法所生成的QA十分的简单。我利用GPT-4简单生成了一个Demo，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Base.png" alt="Demo:直接通过知识图谱生成的QA"><figcaption aria-hidden="true">Demo:直接通过知识图谱生成的QA</figcaption></figure><p>很显然这种数据不具有<mark>多样性</mark>，也不满足我们的要求。我们认为在若干定语修饰后的QA可以极大地丰富数据多样性：</p><ul><li>地毯左面紧挨的儿童椅和行李箱旁的双人床哪个更大？</li><li>空调下面的挂画和墙壁右边的衣服哪个数量更多？</li></ul><p>本质上，我们希望对原有数据增加一定的定语——<mark>将程式化的短语转变为流畅丰富的句子</mark>，效果如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Improve.png" alt="1-Hop描述（右）可以丰富QA内容"><figcaption aria-hidden="true">1-Hop描述（右）可以丰富QA内容</figcaption></figure><p>生成大批量数据离不开大模型的帮助。出于对计算资源以及生成效率的考虑，我们没有选择API或是参数量更大的模型，而是在本地部署Qwen-7B，并期待通过微调可以让其生成我们希望的1-Hop描述，如下图框出部分：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/流程.png" alt="生成QA数据集流程"><figcaption aria-hidden="true">生成QA数据集流程</figcaption></figure><h1 id="方法">方法</h1><h2 id="原理浅析">原理浅析</h2><p>除了SFT之外，人们采用更少计算资源进行微调的方法称为PEFT，其中又包含若干种方法。</p><p>我在网上找到的一个时间轴，可以很好地展示发展历程，如下图：</p><figure><img src="https://oscimg.oschina.net/oscnet/9ac87619-bf4f-41d6-9c94-d7a8cb030acb.png" alt="主流微调方法的发展"><figcaption aria-hidden="true">主流微调方法的发展</figcaption></figure><p>因为显卡资源的限制，我们采用P-tuning来进行微调，从而生成1-Hop描述，<a href="https://arxiv.org/abs/2103.10385">论文原文</a>。</p><p>与Prefix-tuning直接给Prompt增加前缀不同，P-tuning在Prompt中随意加入Embedding后的Virtual Token，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/P-tuning.png" alt="P-tuning结构示意图"><figcaption aria-hidden="true">P-tuning结构示意图</figcaption></figure><h2 id="训练数据">训练数据</h2><p>考虑到时间成本以及Token成本，我们决定在Info中选取<mark>部分数据</mark>，将这一部分数据和利用GPT-4生成的1-Hop描述拼接在一起，形成了微调用的训练数据集。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/数据.png" alt="准备微调数据"><figcaption aria-hidden="true">准备微调数据</figcaption></figure><p>通过将人工制作的模板（如下图）与Info中的信息作为Prompt，我们利用GPT-4进行生成；生成的内容需要进一步通过正则表达式的处理，最终成为1-Hop描述。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT1.png" alt="模板1"><figcaption aria-hidden="true">模板1</figcaption></figure><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT2.png" alt="模板2"><figcaption aria-hidden="true">模板2</figcaption></figure><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT3.png" alt="模板3"><figcaption aria-hidden="true">模板3</figcaption></figure><h2 id="训练过程">训练过程</h2><p>Qwen-7B接收到的Prompt由另一套模板以及Info中的信息组成，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Prompt.png" alt="询问功能的模板"><figcaption aria-hidden="true">询问功能的模板</figcaption></figure><p>代码需要放到HGX集群上跑，但是需要排队很久。之前微调的时候loss从14下降到8左右。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/HGX.png" alt="GPU集群"><figcaption aria-hidden="true">GPU集群</figcaption></figure><h1 id="结果">结果</h1><p>整个对Info进行增强生成1-Hop描述的过程很慢，最终也没有将整个map的3000个视角（1000个场景*3个视角）遍历完。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/结果.png" alt="结果"><figcaption aria-hidden="true">结果</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>实习</tag>
      
      <tag>BIGAI</tag>
      
      <tag>数据生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
