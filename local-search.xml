<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>BIGAI2—微调Qwen-7B</title>
    <link href="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/"/>
    <url>/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在生成QA时，我们希望生成的数据具有$\textcolor{red}{一定的复杂度}$，并且具有$\textcolor{red}{生活化}$的特点。</p><p>最基本的一个想法是：当我们需要某个子图（Region Graph）中的物体信息，便直接从已有信息Info中查找，并送入GPT生成QA；然而，基于这种方法所生成的QA十分的简单。我利用GPT-4简单生成了一个Demo，如下图：</p><p><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Base.png" alt="Demo:直接通过知识图谱生成的QA"></p><p>很显然这种数据不具有$\textcolor{red}{多样性}$，也不满足我们的要求。我们认为在若干定语修饰后的QA可以极大地丰富数据多样性：</p><ul><li>地毯左面紧挨的儿童椅和行李箱旁的双人床哪个更大？</li><li>空调下面的挂画和墙壁右边的衣服哪个数量更多？</li></ul><p>本质上，我们希望对原有数据增加一定的定语——$\textcolor{red}{将程式化的短语转变为流畅丰富的句子}$，效果如下图：</p><p><img src="/Improve.png" alt="Improve"></p><p>生成大批量数据离不开大模型的帮助。出于对计算资源以及生成效率的考虑，我们没有选择API或是参数量更大的模型，而是在本地部署Qwen-7B，并期待通过微调可以让其适应该下游任务，如下图框出部分：</p><p><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/%E6%B5%81%E7%A8%8B.png" alt="生成QA数据集流程"></p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="原理浅析"><a href="#原理浅析" class="headerlink" title="原理浅析"></a>原理浅析</h2><p>除了SFT之外，人们采用更少计算资源进行微调的方法称为PEFT，其中又包含若干种方法。</p><p>我在网上找到的一个时间轴，可以很好地展示发展历程，如下图：</p><p><img src="https://oscimg.oschina.net/oscnet/9ac87619-bf4f-41d6-9c94-d7a8cb030acb.png" alt="主流微调方法的发展"></p><p>因为显卡资源的限制，我们采用P-tuning来进行微调，从而生成1-Hop描述，<a href="https://arxiv.org/abs/2103.10385">论文原文</a>。</p><p>与Prefix-tuning直接给Prompt增加前缀不同，P-tuning在Prompt中随意加入Virtual Token直接转化成的Embedding，如下图：</p><p><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/P-tuning.png" alt="P-tuning结构示意图"></p><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/%E6%95%B0%E6%8D%AE.png" alt="准备微调数据"></p><h3 id="Prompt"><a href="#Prompt" class="headerlink" title="Prompt"></a>Prompt</h3><p>我们人工制定了以下模板，将模板内容以及Info中的物体信息拼接作为Prompt</p><p><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Prompt.png" alt="模板"></p><h3 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h3><p>那么微调用的数据中Prompt对应的Output是哪里来的呢？</p><h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BIGAI</tag>
      
      <tag>大模型</tag>
      
      <tag>实习</tag>
      
      <tag>数据生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
