<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Pytorch加速训练MNIST</title>
    <link href="/2024/08/29/Pytorch%E5%8A%A0%E9%80%9F%E8%AE%AD%E7%BB%83/"/>
    <url>/2024/08/29/Pytorch%E5%8A%A0%E9%80%9F%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[<h1 id="实验过程">0、实验过程</h1><p>为了对比Pytorch中不同方法对于训练速度的提升，采用最基础的<a href="https://blog.csdn.net/qq_45588019/article/details/120935828">MNIST数字识别</a>，基础配置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">64</span><br>learning_rate = <span class="hljs-number">0.01</span><br>momentum = <span class="hljs-number">0.5</span><br>EPOCH = <span class="hljs-number">5</span><br><br>criterion = torch.nn.CrossEntropyLoss()  <br>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)  <br></code></pre></td></tr></table></figure>源码是CPU上跑的，改到GPU上作为一个Baseline：<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;}</style><div class="center"><table><thead><tr class="header"><th style="text-align: center;">方法</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">CPU</td><td style="text-align: center;">97.9</td><td style="text-align: center;">25.16</td></tr><tr class="even"><td style="text-align: center;">GPU（RTX3080）</td><td style="text-align: center;">98.4</td><td style="text-align: center;">20.40</td></tr></tbody></table></div><h1 id="dataloader">1、Dataloader</h1>看到<a href="https://blog.csdn.net/qq_28057379/article/details/115427052">网上</a>有说将<code>num_workers</code>设置成CPU数量一样，但也有的说并非越大越好，可能需要进行实验选择最佳的。在这里测试集准确率参考意义并不大，因为差距很小，并且dataloader不会对准确率造成显著的影响，可能与参数的初始化情况有关<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;  margin-top: auto;}</style><div class="center"><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Baseline</td><td style="text-align: center;">98.4</td><td style="text-align: center;">20.40</td></tr><tr class="even"><td style="text-align: center;"><code>num_workers=4</code></td><td style="text-align: center;">98.3</td><td style="text-align: center;">7.54</td></tr><tr class="odd"><td style="text-align: center;"><code>pin_memory=True</code></td><td style="text-align: center;">98.7</td><td style="text-align: center;">21.32</td></tr><tr class="even"><td style="text-align: center;"><code>num_workers=4，pin_memory=True</code></td><td style="text-align: center;">98.4</td><td style="text-align: center;"><strong>6.14</strong></td></tr></tbody></table></div><h1 id="自动混合精度-amp">2、自动混合精度 AMP</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">scaler = GradScaler(enabled=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">for</span> batch_idx, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader, <span class="hljs-number">0</span>):<br>        inputs, target = data<br>        optimizer.zero_grad()<br><br>        <span class="hljs-keyword">with</span> autocast(enabled=<span class="hljs-literal">True</span>, dtype=torch.float16):<br>            outputs = model(inputs.to(device))<br>            loss = criterion(outputs, target.to(device))<br><br>            scaler.scale(loss).backward()<br>            scaler.step(optimizer)<br>            scaler.update()   <br></code></pre></td></tr></table></figure>在这个实验中AMP并未提速，反而还慢了，猜想是因为数据集规模太小。不过在之前的比赛中，在对大模型推理时使用混合精度确实有减少推理时间<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;}</style><div class="center"><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Baseline</td><td style="text-align: center;">98.4</td><td style="text-align: center;"><strong>20.40</strong></td></tr><tr class="even"><td style="text-align: center;">AMP</td><td style="text-align: center;">98.5</td><td style="text-align: center;">21.83</td></tr></tbody></table></div><h1 id="优化器">3、优化器</h1>除了Baseline中设置了动量参数外，其余皆采用默认参数<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;}</style><div class="center"><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Baseline</td><td style="text-align: center;">98.4</td><td style="text-align: center;">20.40</td></tr><tr class="even"><td style="text-align: center;">Adam</td><td style="text-align: center;">95.2</td><td style="text-align: center;">20.43</td></tr><tr class="odd"><td style="text-align: center;">AdamW</td><td style="text-align: center;">97.5</td><td style="text-align: center;">20.62</td></tr><tr class="even"><td style="text-align: center;">RMSprop</td><td style="text-align: center;">97.2</td><td style="text-align: center;"><strong>20.04</strong></td></tr><tr class="odd"><td style="text-align: center;">Adagrad</td><td style="text-align: center;"><strong>98.8</strong></td><td style="text-align: center;">20.31</td></tr></tbody></table></div><h1 id="归一化">4、归一化</h1><h1 id="学习率">5、学习率</h1><h1 id="batchsize">6、BatchSize</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数组</title>
    <link href="/2024/08/28/%E6%95%B0%E7%BB%84/"/>
    <url>/2024/08/28/%E6%95%B0%E7%BB%84/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="双指针">1、双指针</h1><ol type="1"><li><p><a href="https://leetcode.cn/problems/squares-of-a-sorted-array/">977. Squares of a Sorted Array</a></p><p><img src="https://code-thinking.cdn.bcebos.com/gifs/977.%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E5%B9%B3%E6%96%B9.gif"></p></li></ol><h1 id="滑动窗口">2、滑动窗口</h1><ol type="1"><li><a href="https://leetcode.cn/problems/minimum-size-subarray-sum/">209. Minimum Size Subarray Sum</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>归一化</title>
    <link href="/2024/08/27/%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <url>/2024/08/27/%E5%BD%92%E4%B8%80%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="batchnorm">1、BatchNorm</h1><h1 id="layernorm">2、LayerNorm</h1><p>针对一个样本所有特征计算均值和方差，然后对样本进行归一化</p><p>减少内部协变量偏移（Internal Covariate Shift）： 内部协变量偏移是指在深度神经网络的训练过程中，每一层输入的分布会发生变化，导致网络的训练变得困难。层归一化通过对每一层的输入进行归一化处理，可以减少内部协变量偏移，使得每一层的输入分布更加稳定。 <strong>稳定梯度</strong>： 层归一化有助于保持每一层输出的均值和方差稳定，从而使得梯度的传播更加稳定。这有助于减少梯度消失或梯度爆炸的问题，提高梯度在网络中的流动性，加快训练速度。</p><h1 id="instancenorm">3、InstanceNorm</h1><h1 id="rmsnorm">4、RMSNorm</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>归一化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>激活函数</title>
    <link href="/2024/08/26/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <url>/2024/08/26/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="激活函数">1、激活函数</h1><ol type="1"><li><p><code>sigmoid</code>：<span class="math inline">\(\sigma(x)=\frac{1}{1+e^{-x}}\)</span></p><ul><li><p><span class="math inline">\(\rm max\{\sigma&#39;(x)\}=0.25&lt;1\)</span>，容易出现梯度消失</p></li><li><p>输出均值不为0，导致收敛变慢</p><p>​ <a href="https://cloud.tencent.com/developer/article/1829621">非零均值？激活函数也太硬核了</a></p><p>​ <a href="https://liam.page/2018/04/17/zero-centered-active-function/">谈谈激活函数以0为中心 的问题</a></p></li></ul></li><li><p><code>ReLU</code></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>激活函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer</title>
    <link href="/2024/08/24/Transformer/"/>
    <url>/2024/08/24/Transformer/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="结构">1、结构</h1><h1 id="特点">2、特点</h1><ol type="1"><li>支持并行计算，提高推理速度👍</li><li>捕捉长距离依赖关系👍</li><li>计算成本高👎</li><li>对序列长度敏感👎</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>链表</title>
    <link href="/2024/08/24/%E9%93%BE%E8%A1%A8/"/>
    <url>/2024/08/24/%E9%93%BE%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="链表删除头结点">1、链表删除头结点</h1><ul><li>设置虚拟头结点</li><li>将原来链表的头指针向后移动</li></ul><ol type="1"><li><p><a href="https://leetcode.cn/problems/remove-linked-list-elements/">203. Remove Linked List Elements</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 虚拟头节点法</span><br><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeElements</span>(<span class="hljs-params">self, head: <span class="hljs-type">Optional</span>[ListNode], val: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<br>        <span class="hljs-comment"># 创建虚拟头部节点以简化删除过程</span><br>        dummy_head = ListNode(<span class="hljs-built_in">next</span> = head)<br>        <br>        <span class="hljs-comment"># 遍历列表并删除值为val的节点</span><br>        current = dummy_head<br>        <span class="hljs-keyword">while</span> current.<span class="hljs-built_in">next</span>:<br>            <span class="hljs-keyword">if</span> current.<span class="hljs-built_in">next</span>.val == val:<br>                current.<span class="hljs-built_in">next</span> = current.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">else</span>:<br>                current = current.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-keyword">return</span> dummy_head.<span class="hljs-built_in">next</span><br></code></pre></td></tr></table></figure></li></ol><h1 id="反转链表">2、反转链表</h1><figure><img src="https://code-thinking.cdn.bcebos.com/gifs/206.%E7%BF%BB%E8%BD%AC%E9%93%BE%E8%A1%A8.gif" alt="反转链表"><figcaption aria-hidden="true">反转链表</figcaption></figure><ol type="1"><li><p><a href="https://leetcode.cn/problems/reverse-linked-list/">206. Reverse Linked List</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 双指针法</span><br><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reverseList</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; ListNode:<br>        cur = head   <br>        pre = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">while</span> cur:<br>            temp = cur.<span class="hljs-built_in">next</span> <span class="hljs-comment"># 保存一下 cur的下一个节点，因为接下来要改变cur-&gt;next</span><br>            cur.<span class="hljs-built_in">next</span> = pre <span class="hljs-comment">#反转</span><br>            <span class="hljs-comment">#更新pre、cur指针</span><br>            pre = cur<br>            cur = temp<br>        <span class="hljs-keyword">return</span> pre<br></code></pre></td></tr></table></figure></li></ol><h1 id="快慢指针删除链表倒数第n个节点">3、快慢指针删除链表倒数第n个节点</h1><ol type="1"><li><p><a href="https://leetcode.cn/problems/remove-nth-node-from-end-of-list/">19. Remove Nth Node From End of List</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeNthFromEnd</span>(<span class="hljs-params">self, head: ListNode, n: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:<br>        <span class="hljs-comment"># 创建一个虚拟节点，并将其下一个指针设置为链表的头部</span><br>        dummy_head = ListNode(<span class="hljs-number">0</span>, head)<br>        <br>        <span class="hljs-comment"># 创建两个指针，慢指针和快指针，并将它们初始化为虚拟节点</span><br>        slow = fast = dummy_head<br>        <br>        <span class="hljs-comment"># 快指针比慢指针快 n+1 步</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>):<br>            fast = fast.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-comment"># 移动两个指针，直到快速指针到达链表的末尾</span><br>        <span class="hljs-keyword">while</span> fast:<br>            slow = slow.<span class="hljs-built_in">next</span><br>            fast = fast.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-comment"># 通过更新第 (n-1) 个节点的 next 指针删除第 n 个节点</span><br>        slow.<span class="hljs-built_in">next</span> = slow.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-keyword">return</span> dummy_head.<span class="hljs-built_in">next</span><br></code></pre></td></tr></table></figure></li></ol><h1 id="环形链表">4、环形链表</h1><ol type="1"><li><p><a href="https://leetcode.cn/problems/linked-list-cycle-ii/">142. Linked List Cycle II</a></p><p>这个题目首先要利用快慢指针（步长分别为1、2）求出一个圈的长度是多少，然后利用删除链表中倒数第n个节点中的思想再次使用快慢指针（一个指针领先头指针一个圈的长度）求出入圈节点；下图为另一种做法：上</p><figure><img src="https://code-thinking.cdn.bcebos.com/gifs/142.%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8II%EF%BC%88%E6%B1%82%E5%85%A5%E5%8F%A3%EF%BC%89.gif" alt="另一种做法"><figcaption aria-hidden="true">另一种做法</figcaption></figure></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
      <tag>链表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode 8-19</title>
    <link href="/2024/08/24/%E9%93%BE%E8%A1%A8/24LeetCode%200819/"/>
    <url>/2024/08/24/%E9%93%BE%E8%A1%A8/24LeetCode%200819/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="排序链表">148.<a href="https://leetcode.cn/problems/sort-list/?envType=study-plan-v2&amp;envId=top-100-liked">排序链表</a></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sortList</span>(<span class="hljs-params">self, head: <span class="hljs-type">Optional</span>[ListNode]</span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> head:<span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br>        p=head<br>        node=[]<br>        <span class="hljs-keyword">while</span> p:<br>            node.append([p,p.val])<br>            p=p.<span class="hljs-built_in">next</span><br>        <br>        node.sort(key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">1</span>])<br>        <span class="hljs-built_in">print</span>(node)<br><br>        p=node[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(node)):<br>            p.<span class="hljs-built_in">next</span>=node[_][<span class="hljs-number">0</span>]<br>            p=p.<span class="hljs-built_in">next</span><br><br>        <span class="hljs-keyword">return</span> node[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br><br></code></pre></td></tr></table></figure><p>最开始这么写，说我内存超了，后来才注意到空间复杂度是有要求的</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TSCIL论文笔记</title>
    <link href="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="阅读论文">〇、阅读论文</h1><ol type="1"><li><a href="https://arxiv.org/abs/1904.07734">增量学习的三种场景及方法：Three scenarios for continual learning</a></li><li><a href="https://arxiv.org/abs/2112.08654">预训练模型图像类增量学习：Learning to Prompt for Continual Learning</a></li><li><a href="https://arxiv.org/abs/2402.12035">时间序列类增量学习的基准：Class-incremental Learning for Time Series:Benchmark and Evaluation</a></li><li><a href="https://arxiv.org/abs/2204.04799">DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</a></li><li><a href="https://arxiv.org/abs/2402.03885">时间序列大模型：MOMENT: A Family of Open Time-series Foundation Models</a></li><li><a href="https://arxiv.org/abs/2403.20317">Convolutional Prompting meets Language Models for Continual Learning</a></li></ol><h1 id="一相关工作">一、相关工作</h1><h2 id="增量学习的三种场景及方法">1. 增量学习的三种场景及方法</h2><h3 id="实验方法">1.1 实验方法</h3><ol type="1"><li>正则化（SI、EWC）</li><li>重放（Replay）<ol type="1"><li>用之前模型对当前任务的Input进行标注生成伪数据（LwF）</li><li>生成新数据（DGR、DGR+distill）</li><li>原始数据重现（可能会有隐私或内存问题）</li></ol></li><li>Exemplars（特征提取+最近类均值+重放：iCaRL）</li></ol><h3 id="实验结果">1.2 实验结果</h3><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/MNIST结果.png" alt="实验结果对比：正则化的效果普遍不太行"><figcaption aria-hidden="true">实验结果对比：正则化的效果普遍不太行</figcaption></figure><h2 id="预训练模型图像类增量学习">2. 预训练模型图像类增量学习</h2><h3 id="实验方法-1">2.1 实验方法</h3><ol type="1"><li>设Input为<span class="math inline">\(x\)</span>，通过<span class="math inline">\(q(x)\)</span>进行映射</li><li>计算<span class="math inline">\(q(x)\)</span>与Key的余弦相似度并选择TopN（同一Prompt被选择的次数越多，下次被选择的概率越小）</li><li>将TopN向量，以及进入Embedding层的Input拼接，并放入预训练模型</li></ol><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/L2P.png" alt="L2P"><figcaption aria-hidden="true">L2P</figcaption></figure><h4 id="vit">2.1.1 ViT</h4><p>在细读论文时需要一些ViT的知识，于是找到了这篇博客：<a href="https://blog.csdn.net/MengYa_Dream/article/details/126600748">ViT的cls token作用</a></p><ol type="1"><li>论文中假设输入的2D图像<span class="math inline">\(x \in \mathbb{R}^{H \times W \times C}\)</span>中<span class="math inline">\(H\)</span>，<span class="math inline">\(W\)</span>，<span class="math inline">\(C\)</span>分别代表高度，宽度和通道数</li><li><span class="math inline">\(f=f_r \circ f_e\)</span>是一个复合函数，指的是将输入embedding后送入自注意力层的结果</li><li>ViT中，图像需要切分为若干patch；在这里flattened 2D patches <span class="math inline">\(x_p \in \mathbb{R}^{L \times (S^2 \cdot C)}\)</span>，其中<span class="math inline">\(L\)</span>为patches个数，<span class="math inline">\(S\)</span>为patch size</li><li>为了简化表示，<span class="math inline">\(x_p\)</span>的第一个token被当做是<code>[class token]</code></li><li>embedding layer的作用<span class="math inline">\(f_e:\mathbb{R}^{L \times (S^2 \cdot C)} \rightarrow \mathbb{R}^{L \times D}\)</span>，其中<span class="math inline">\(D\)</span>是嵌入维度</li><li>一个Prompt可以看作是$P_e^{L_p D} <span class="math inline">\(，其中\)</span>L_p$是Prompt的长度</li><li>将Prompt和Input拼接起来可以得到<span class="math inline">\(x_p=[P_e;x_e]\)</span></li><li>送入预训练模型后，即<span class="math inline">\(f=f_r(x_p)\)</span></li></ol><h4 id="prompt-pool">2.1.2 Prompt Pool</h4><p>为什么要采用Pool的原因有三：</p><ol type="1"><li>在推理的时候task identity是不得而知的，因此为每个task设置一个prompt是不可行的</li><li>即使推理时上述信息可以得知，那么task-independent prompt可能阻止了相似任务间的信息共享</li><li>如果只用一个prompt，则会造成灾难性遗忘</li></ol><p>于是定义Prompt集合：<span class="math inline">\(P = \{P_1, P_2, \cdots , P_M \}\)</span>，则ViT的输入为：<span class="math inline">\(x_p = [P_{s_1} ; \cdots ; P_{s_N} ; x_e], 1 ≤ N ≤ M\)</span></p><p>Prompt Pool中其实是Key-Value pair：<span class="math inline">\(\{(k_1, P_1), (k_2, P_2), \cdots , (k_M , P_M )\},k_i \in \mathbb{R}^{D_k}\)</span></p><div class="note note-info">            <p>根据论文来看，M为所有Prompt 的数量，是一个可以定义的参数</p>          </div><h4 id="prompt-query">2.1.3 Prompt Query</h4><ol type="1"><li>Query应仅跟输入实例有关，并且没有可学习的参数；定义Query Function：<span class="math inline">\(q : \mathbb{R}^{H\times W \times C} → \mathbb{R}^{D_k}\)</span></li><li>作者用了ViT作为feature extractor：<span class="math inline">\(q(x) = f (x)[0,:]\)</span>，其实就是<code>[class token]</code>对应的向量<ul><li>同时，作者指出用ConvNet也是可行的</li></ul></li><li>定义相似度计算函数<span class="math inline">\(\gamma : \mathbb{R}^{D_k} \times \mathbb{R}^{D_k} \rightarrow \mathbb{R}\)</span>，作者发现余弦相似度就很好</li><li>问题简化为<span class="math inline">\(K_x = \mathop{argmin}\limits_{\{s_i\}^N_{i=1}\in[1,M ]} \sum\limits_{i=1}^N \gamma (q(x), k_{s_i} )\)</span>，其中<span class="math inline">\(K_x\)</span>是所有Key的一个子集<ul><li>为了让每个Prompt都有机会被引用，训练时改写为<span class="math inline">\(K_x = \mathop{argmin}\limits_{\{s_i\}^N_{i=1}\in[1,M ]} \sum\limits_{i=1}^N \gamma (q(x), k_{s_i} )\cdot h_{s_i}\)</span></li></ul></li></ol><h4 id="loss-function">2.1.4 Loss Function</h4><p><span class="math display">\[\mathop{\rm min} \limits_{P,K,\phi} \mathcal{L}(g_{\phi}(f^{avg}_r (x_p)), y) + \lambda\sum\limits_{K_x}  \gamma (q(x), k_{s_i} ),\quad s.t. K_x在2.1.3中已经得到\]</span></p><h3 id="实验结果-1">2.2 实验结果</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/CIFAR.png"></p><h2 id="时间序列类增量学习的基准">3. 时间序列类增量学习的基准</h2><h3 id="实验方法-2">3.1 实验方法</h3><h4 id="正则化">3.1.1 正则化</h4><p>基于正则化的方法（LwF、MAS、<span class="math inline">\(DT^2W\)</span>）只在UCI-HAR和UWave等任务较少的简单数据集中表现出明显的优势</p><h4 id="归一化bn-vs-ln">3.1.2 归一化：BN vs LN</h4><p>在大多数情况下使用LN的效果要比BN更好</p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Norm.png" alt="Norm"><figcaption aria-hidden="true">Norm</figcaption></figure><h4 id="rehearsal-baseder-vs-gr">3.1.3 Rehearsal-based：ER vs GR</h4><p>GR在简单数据上较好，甚至好过ER，复杂数据上表现不佳；可能是因为难以生成复杂数据，以及无法控制生成的类别</p><h4 id="meomory-budget在bn和ln上的差异">3.1.4 Meomory budget在BN和LN上的差异</h4><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/memory.png"></p><ul><li>基于ER的方法通常性能会随着Memory budget的增大而提高，到达一定程度会趋于饱和</li><li>在内存足够时，BN在除ASER的方法都与Offline有很大差异，因为随着任务数量增加<span class="math inline">\(B_{M}\)</span>中旧样本比例会减少；LN则接近Offline</li></ul><h4 id="分类器的选择">3.1.5 分类器的选择</h4><p>分类器选择取决于方法与数据集，在ER上的区别并不明显</p><h2 id="双提示增量学习">4. 双提示增量学习</h2><h1 id="二l2p">二、L2P</h1><h2 id="踩坑">1. 踩坑</h2><p>在服务器上部署之后，Github上提到没有CIFAR-100的话，在<code>datasets.py</code>更改如下字段：</p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/教程.png" alt="Github上的教程"><figcaption aria-hidden="true">Github上的教程</figcaption></figure><p>但其实不用改的，本来就是<code>True</code></p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/源码1.png" alt="datasets.py"><figcaption aria-hidden="true">datasets.py</figcaption></figure><p>不过在运行的时候会报这个错：</p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/报错.png" alt="报错说没有cifar100_12p这个路径"><figcaption aria-hidden="true">报错说没有cifar100_12p这个路径</figcaption></figure><p>后来找到了一个脚本文件<code>train_cifar100_l2p.sh</code>执行，但本地并没有<code>local_datasets</code>路径：</p><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/路径.png"></p><p>这个报错上面提到，这个数据集是在<code>torchvision</code>里面<code>cifar.py</code>下载的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">[rank0]:   File <span class="hljs-string">&quot;/home/eee/zym/l2p-pytorch/datasets.py&quot;</span>, line <span class="hljs-number">107</span>, <span class="hljs-keyword">in</span> get_dataset<br>[rank0]:   dataset_train = datasets.CIFAR100(args.data_path, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform_train)<br>[rank0]:   File <span class="hljs-string">&quot;/home/eee/anaconda3/envs/zym/lib/python3.8/site-packages/torchvision/datasets/cifar.py&quot;</span>, line <span class="hljs-number">66</span>, <span class="hljs-keyword">in</span> __init__<br>[rank0]:     <span class="hljs-variable language_">self</span>.download()<br></code></pre></td></tr></table></figure><p>新建了<code>local_datasets</code>后运行脚本文件，还是报错；最后发现脚本路径写的有问题，改成下面即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">--data-path ./local_datasets/ \<br></code></pre></td></tr></table></figure><h2 id="分析">2. 分析</h2><h3 id="代码结构">2.1 代码结构</h3><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/结构.png" alt="代码结构"><figcaption aria-hidden="true">代码结构</figcaption></figure><p>关于为什么要出现<code>original_model</code>和<code>model</code>，是因为作者在这里做了消融实验，微调了model中的部分参数。不过从结果来看，并没有比原始论文的要好。</p><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/冻结.png"></p><h3 id="运行结果">2.2 运行结果</h3><p>注意到Loss出现了负值，是因为采用的多元交叉熵损失函数。</p><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/loss.png"></p><h1 id="三本文设计">三、本文设计</h1><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/流程.png"></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>类增量学习</tag>
      
      <tag>微调</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BIGAI1-基于Langchain构建用于数据生成Agent</title>
    <link href="/2024/08/06/%E5%9F%BA%E4%BA%8ELangchain%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90Agent/"/>
    <url>/2024/08/06/%E5%9F%BA%E4%BA%8ELangchain%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90Agent/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><p>类似的文章已经在<a href="https://blog.csdn.net/sersama/article/details/139179060?spm=1001.2014.3001.5502">CSDN</a>发布过了，在这里进行简单总结。</p><h1 id="背景">背景</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>实习</tag>
      
      <tag>BIGAI</tag>
      
      <tag>数据生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>百度-基于大模型的广告检索</title>
    <link href="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/"/>
    <url>/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="数据分析以及初赛方法">数据分析以及初赛方法</h1><h2 id="query落地页核心词长度分布">Query、落地页、核心词长度分布</h2><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/query.png" alt="query"><figcaption aria-hidden="true">query</figcaption></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/lp.png" alt="lp"><figcaption aria-hidden="true">lp</figcaption></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/ct.png" alt="ct"><figcaption aria-hidden="true">ct</figcaption></figure><h2 id="广告id分布">广告ID分布</h2><p>在发现Query中的ID远少于广告ID数量后，我想统计ID的分布。最开始采用柱状图，但由于数据量过大，最后绘制出的图像不直观。因此，我向Kimi问到了一种估计分布密度的方法<a href="https://blog.csdn.net/weixin_39910711/article/details/107307509">KDE</a>，这是一种非参数估计方法，相对于参数估计（如：最大似然估计）不需要对数据的分布有先验的认识：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> gaussian_kde<br><br>json file =<span class="hljs-string">&#x27;/home/zym/桌面/FEIJIANG/Doc/Doc_train_ultra.json&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(json file,<span class="hljs-string">&#x27;r&#x27;</span>,encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<span class="hljs-keyword">as</span> file:<br>    js =[json.loads(line)<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> file]<br>    <br>tgt_values=[ _[<span class="hljs-string">&#x27;tgt&#x27;</span>]<span class="hljs-keyword">for</span> <span class="hljs-keyword">in</span> js]<br>tgt_array=np.array(tgt_values,dtype=np.float64)<br><br><span class="hljs-comment"># 将列表转换为NumPy数组</span><br>tgt_array = np.array(tgt_values, dtype=np.float64)<br><br><span class="hljs-comment"># 计算核密度估计，使用高斯核</span><br>kde = gaussian_kde(tgt_array)<br><br><span class="hljs-comment"># 绘制平滑的曲线</span><br>x = np.linspace(np.<span class="hljs-built_in">min</span>(tgt_array), np.<span class="hljs-built_in">max</span>(tgt_array), <span class="hljs-number">1000</span>)<br>y = kde(x)<br></code></pre></td></tr></table></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/ID分布.png" alt="初赛数据的广告ID分布"><figcaption aria-hidden="true">初赛数据的广告ID分布</figcaption></figure><h2 id="训练过程">训练过程</h2><p>在论文中</p><h1 id="baseline">Baseline</h1><p>数据集中有88wDoc，因为论文中提到直接索引效果较好，因此取落地页连续的短语作为Doc；特别地，观察到Doc长度分布不均，因此在生成Doc时设定为长度越长、采样次数越多。最终得到880wDoc，在第一阶段进行索引学习时4000steps已趋于收敛，遂暂停。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/简单Doc.png" alt="简单构建Doc"><figcaption aria-hidden="true">简单构建Doc</figcaption></figure><p>对于Query，按Click进行增强，从500w得到1200w数据。在上一步得到的权重上训练，效果还可以。</p><h1 id="尝试一semantic-docid">尝试一：Semantic DocID</h1><p>官方所给的数据集中ID是没有规律的，不同的广告内容ID可能邻近，相似的广告ID可能很远，因此这对生成式模型而言，像是在做一个“多分类”的任务。在这篇<a href="https://arxiv.org/abs/2309.13335">Model-enhanced Vector Index</a>论文中提到利用Residual Quantization进行层次聚类效果可能会好，于是考虑用模型对广告内容进行Embedding，但因为本地没有显卡用，并且在AIstudio又不能用Pytorch，因此采用<a href="https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers/ERNIE/contents.html">Ernie-3.0-mini</a>。</p><h2 id="q1embedding文件太大">Q1：Embedding文件太大</h2><p>即使采用mini，在对约29000个句子（3%）进行Embedding之后，我的json文件就已经达到了220MB</p><p><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/mini.png"></p><p>文件存储格式如下</p><p><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/json.png"></p><h2 id="q2内存过大">Q2：内存过大</h2><p>因为词袋方法耗时更长，占用内存更大，后来又再次尝试使用Embedding。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;/home/aistudio/embed.json&quot;</span>,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    data=[json.loads(line)<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f]<br></code></pre></td></tr></table></figure><p>居然在读取的时候内存就满了。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/内存.png" alt="内存满了"><figcaption aria-hidden="true">内存满了</figcaption></figure><h1 id="尝试二词袋">尝试二：词袋</h1><p>这里使用Paddle里的Taskflow进行分词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./embed.json&quot;</span>,<span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(res)+<span class="hljs-number">1</span>)):<br>        seg = Taskflow(<span class="hljs-string">&quot;word segmentation&quot;</span>)temp = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x:x!=,<span class="hljs-string">&#x27;,seg(res[str(i)])))</span><br><span class="hljs-string">        # 使用counter计算每个分词出现的次数</span><br><span class="hljs-string">        word count= counter(temp)</span><br><span class="hljs-string">        #按照出现次数进行升序排序</span><br><span class="hljs-string">        sorted word count = dict(sorted(word count.items(), key=lambda item: item[1]))</span><br><span class="hljs-string">        json.dump(&#123;&quot;tgt&quot;:i,&quot;bow&quot;: sorted word count&#125;,f,ensure ascii=False)</span><br></code></pre></td></tr></table></figure><p>最终分词结果文件很大，没有进一步处理。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/分词.png" alt="分词结果"><figcaption aria-hidden="true">分词结果</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>百度</tag>
      
      <tag>搜广推</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BIGAI2—微调Qwen-7B生成1-Hop描述</title>
    <link href="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/"/>
    <url>/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="背景">背景</h1><p>在生成QA时，我们希望生成的数据具有<mark>一定的复杂度</mark>，并且具有<mark>生活化</mark>的特点。</p><p>最基本的一个想法是：当我们需要某个子图（Region Graph）中的物体信息，便直接从已有信息Info中查找，并送入GPT生成QA；然而，基于这种方法所生成的QA十分的简单。我利用GPT-4简单生成了一个Demo，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Base.png" alt="Demo:直接通过知识图谱生成的QA"><figcaption aria-hidden="true">Demo:直接通过知识图谱生成的QA</figcaption></figure><p>很显然这种数据不具有<mark>多样性</mark>，也不满足我们的要求。我们认为在若干定语修饰后的QA可以极大地丰富数据多样性：</p><ul><li>地毯左面紧挨的儿童椅和行李箱旁的双人床哪个更大？</li><li>空调下面的挂画和墙壁右边的衣服哪个数量更多？</li></ul><p>本质上，我们希望对原有数据增加一定的定语——<mark>将程式化的短语转变为流畅丰富的句子</mark>，效果如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Improve.png" alt="1-Hop描述（右）可以丰富QA内容"><figcaption aria-hidden="true">1-Hop描述（右）可以丰富QA内容</figcaption></figure><p>生成大批量数据离不开大模型的帮助。出于对计算资源以及生成效率的考虑，我们没有选择API或是参数量更大的模型，而是在本地部署Qwen-7B，并期待通过微调可以让其生成我们希望的1-Hop描述，如下图框出部分：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/流程.png" alt="生成QA数据集流程"><figcaption aria-hidden="true">生成QA数据集流程</figcaption></figure><h1 id="方法">方法</h1><h2 id="原理浅析">原理浅析</h2><p>除了SFT之外，人们采用更少计算资源进行微调的方法称为PEFT，其中又包含若干种方法。</p><p>我在网上找到的一个时间轴，可以很好地展示发展历程，如下图：</p><figure><img src="https://oscimg.oschina.net/oscnet/9ac87619-bf4f-41d6-9c94-d7a8cb030acb.png" alt="主流微调方法的发展"><figcaption aria-hidden="true">主流微调方法的发展</figcaption></figure><p>因为显卡资源的限制，我们采用P-tuning来进行微调，从而生成1-Hop描述，<a href="https://arxiv.org/abs/2103.10385">论文原文</a>。</p><p>与Prefix-tuning直接给Prompt增加前缀不同，P-tuning在Prompt中随意加入Embedding后的Virtual Token，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/P-tuning.png" alt="P-tuning结构示意图"><figcaption aria-hidden="true">P-tuning结构示意图</figcaption></figure><h2 id="训练数据">训练数据</h2><p>考虑到时间成本以及Token成本，我们决定在Info中选取<mark>部分数据</mark>，将这一部分数据和利用GPT-4生成的1-Hop描述拼接在一起，形成了微调用的训练数据集。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/数据.png" alt="准备微调数据"><figcaption aria-hidden="true">准备微调数据</figcaption></figure><p>通过将人工制作的模板（如下图）与Info中的信息作为Prompt，我们利用GPT-4进行生成；生成的内容需要进一步通过正则表达式的处理，最终成为1-Hop描述。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT1.png" alt="模板1"><figcaption aria-hidden="true">模板1</figcaption></figure><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT2.png" alt="模板2"><figcaption aria-hidden="true">模板2</figcaption></figure><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT3.png" alt="模板3"><figcaption aria-hidden="true">模板3</figcaption></figure><h2 id="训练过程">训练过程</h2><p>Qwen-7B接收到的Prompt由另一套模板以及Info中的信息组成，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Prompt.png" alt="询问功能的模板"><figcaption aria-hidden="true">询问功能的模板</figcaption></figure><p>代码需要放到HGX集群上跑，但是需要排队很久。之前微调的时候loss从14下降到8左右。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/HGX.png" alt="GPU集群"><figcaption aria-hidden="true">GPU集群</figcaption></figure><h1 id="结果">结果</h1><p>整个对Info进行增强生成1-Hop描述的过程很慢，最终也没有将整个map的3000个视角（1000个场景*3个视角）遍历完。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/结果.png" alt="结果"><figcaption aria-hidden="true">结果</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微调</tag>
      
      <tag>实习</tag>
      
      <tag>BIGAI</tag>
      
      <tag>数据生成</tag>
      
      <tag>大模型</tag>
      
      <tag>P-tuning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
