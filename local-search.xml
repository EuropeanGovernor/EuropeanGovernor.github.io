<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>参数高效微调</title>
    <link href="/2024/09/07/%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/"/>
    <url>/2024/09/07/%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>TSCIL论文笔记·II</title>
    <link href="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/"/>
    <url>/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;  margin-top: 20px;}</style><h1 id="时间线">〇、时间线</h1><p><strong>9月4日~9月6日</strong></p><ol type="1"><li>冻结Transformer参数，只利用MOMENT的分类器在Benchmark上进行训练与测试，在3个简单数据集上效果很好（见2.2）</li><li>利用T-SNE进行降维，没有得到有启发的信息；随后尝试调参（Batchsize、Lr）、解冻Transformer参数来观察<code>GrabMyo</code>上的效果</li><li>阅读综述及相关论文</li><li>改小训练集，重新训练<code>Grabmyo</code></li></ol><h1 id="一相关工作">一、相关工作</h1><ol type="1"><li><a href="https://arxiv.org/abs/2402.02713">Position: What Can Large Language Models Tell Us about Time Series Analysis</a></li><li><a href="https://arxiv.org/abs/2403.14735">Foundation Models for Time Series Analysis: A Tutorial and Survey</a></li><li><a href="https://arxiv.org/abs/2401.16386">Continual Learning with Pre-Trained Models: A Survey</a></li><li><a href="https://arxiv.org/abs/2303.07338">SimpleCIL &amp; APER：Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need</a></li></ol><h2 id="simplecil-aper">4、SimpleCIL &amp; APER</h2><figure><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/APER.png" alt="APER框架"><figcaption aria-hidden="true">APER框架</figcaption></figure><h3 id="表示">4.1 表示</h3><ul><li>训练任务：<span class="math inline">\(\{\mathcal D^1,\mathcal D^2,\cdots,\mathcal D^b\}\)</span></li><li>Prototype：<span class="math inline">\({\rm p_i}=\frac{1}{K}\sum\limits_{j=1}^{|\mathcal D^b|}\mathbb I(y_j=i)\phi(x_j)，K=\sum\limits_{j=1}^{|\mathcal D^b|}\mathbb I(y_j=i)，\mathbb I(\cdot)\)</span>为示性函数</li><li>分类器：<span class="math inline">\(f(x)=W^T\phi(x)，\phi(\cdot)\)</span>为embedding函数，<span class="math inline">\(W\in\mathbb R^{d\times |y_b|}\)</span>是分类头</li></ul><h3 id="算法">4.2 算法</h3><p><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/APER算法.png"></p><ol type="1"><li><p>PTM添加parameter-efficient module后在<span class="math inline">\(\mathcal D^1\)</span>上微调得到AdaPTM</p><ul><li><p>按序微调模型会导致灾难性遗忘</p><figure><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/Adapt.png" alt="微调前T个任务的结果"><figcaption aria-hidden="true">微调前T个任务的结果</figcaption></figure></li><li><p>因为使用prototype-based分类器，因此多次微调会导致前后prototype的特征不兼容</p><blockquote><p>Since we utilize a prototype-based classifier, tuning the model with multiple stages will result in incompatible features between former and new prototypes.</p></blockquote></li></ul></li><li><p>将PTM和AdaPTM的embedding层冻结（只训练分了里头和AdaModule里的参数）</p></li><li><p>对于每一个任务，计算其数据的Prototype并替代分类头的权重</p></li><li><p>通过计算余弦相似度来获得分类结果</p></li></ol><h3 id="adapt方法aper框架图的中右部分">4.3 Adapt方法（APER框架图的中、右部分）</h3><ul><li>Visual Prompt Tuning（VPT）：适合于ViT<ul><li>VPT-Deep：在每一个注意力层加Prompt</li><li>VPT-Shallow：只在第一层加Prompt</li></ul></li><li>Scale &amp; Shift（SSF）：<span class="math inline">\(x_{output}=\gamma\otimes x_{input}+\beta\)</span>，从而将分布适应于新任务</li><li>Adapter：<span class="math inline">\({\rm MLP}(x_l)+{\rm RELU}(x_{l}W_{down})W_{up}\)</span></li><li>Batch Normalization Tuning：适合于CNN-based模型</li></ul><h3 id="实验结果">4.4 实验结果</h3><p><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/APER消融.png"></p><p><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/APER结果.png"></p><h1 id="二moment">二、MOMENT</h1><h2 id="测试代码">2.1 测试代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.path.append(<span class="hljs-string">&quot;/home/eee/zym/&quot;</span>)<br>sys.path.append(<span class="hljs-string">&quot;/home/eee/zym/TSCIL/&quot;</span>)<br>sys.path.append(<span class="hljs-string">&quot;/home/eee/zym/TSCIL/utils/&quot;</span>)<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt <br><span class="hljs-keyword">from</span> momentfm <span class="hljs-keyword">import</span> MOMENTPipeline<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> lr_scheduler<br><span class="hljs-keyword">from</span> EarlyStop <span class="hljs-keyword">import</span> EarlyStopping<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader,Dataset<br><span class="hljs-keyword">from</span> stream <span class="hljs-keyword">import</span> IncrementalTaskStream,get_cls_order<br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>DATA=<span class="hljs-string">&quot;wisdm&quot;</span><br><span class="hljs-comment"># [&#x27;har&#x27;, &#x27;uwave&#x27;, &#x27;dailysports&#x27;, &#x27;grabmyo&#x27;, &#x27;wisdm&#x27;,&#x27;ninapro&#x27;, &#x27;sines&#x27;]</span><br><span class="hljs-comment"># ============================初始化MOMENT============================</span><br>model = MOMENTPipeline.from_pretrained(<br>    <span class="hljs-string">&quot;AutonLab/MOMENT-1-large&quot;</span>, <br>    model_kwargs=&#123;<br>        <span class="hljs-string">&#x27;task_name&#x27;</span>: <span class="hljs-string">&#x27;classification&#x27;</span>,<br>        <span class="hljs-string">&#x27;n_channels&#x27;</span>: <span class="hljs-number">3</span>,<br>        <span class="hljs-string">&#x27;num_class&#x27;</span>: <span class="hljs-number">18</span>,<br>        <span class="hljs-string">&#x27;freeze_encoder&#x27;</span>: <span class="hljs-literal">True</span>, <span class="hljs-comment"># Freeze the patch embedding layer</span><br>        <span class="hljs-string">&#x27;freeze_embedder&#x27;</span>: <span class="hljs-literal">True</span>, <span class="hljs-comment"># Freeze the transformer encoder</span><br>        <span class="hljs-string">&#x27;freeze_head&#x27;</span>: <span class="hljs-literal">False</span>, <span class="hljs-comment"># The linear forecasting head must be trained</span><br>    &#125;, <br>   )<br>model.init()<br>model.to(device)<br><br><span class="hljs-comment"># ============================获取数据集============================</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data, targets</span>):<br>        <span class="hljs-variable language_">self</span>.data = data<br>        <span class="hljs-variable language_">self</span>.targets = targets<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.data)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.data[idx], <span class="hljs-variable language_">self</span>.targets[idx]<br><br>cls_order = get_cls_order(DATA, <span class="hljs-literal">False</span>)<br>task_stream = IncrementalTaskStream(data=DATA, scenario=<span class="hljs-string">&#x27;class&#x27;</span>, cls_order=cls_order,split=<span class="hljs-string">&#x27;all&#x27;</span>)<br>(x_train, y_train), (x_val, y_val), (x_test, y_test) = task_stream.setup_offline()<br>x_train,x_val,x_test=np.transpose(x_train,(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)),np.transpose(x_val,(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)),np.transpose(x_test,(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>))<br><br>train_dataloader = DataLoader(MyDataset(x_train,y_train), batch_size=<span class="hljs-number">64</span>, num_workers=<span class="hljs-number">4</span>,pin_memory=<span class="hljs-literal">True</span>,shuffle=<span class="hljs-literal">True</span>)<br>val_dataloader = DataLoader(MyDataset(x_val,y_val), batch_size=<span class="hljs-number">64</span>, num_workers=<span class="hljs-number">4</span>,pin_memory=<span class="hljs-literal">True</span>,shuffle=<span class="hljs-literal">True</span>)<br>test_dataloader = DataLoader(MyDataset(x_test,y_test), batch_size=<span class="hljs-number">64</span>, num_workers=<span class="hljs-number">4</span>,pin_memory=<span class="hljs-literal">True</span>,shuffle=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># ============================超参数设置============================</span><br>criterion = nn.CrossEntropyLoss()<br>optimizer = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br>scheduler=lr_scheduler.StepLR(optimizer, step_size=<span class="hljs-number">1</span>, gamma=<span class="hljs-number">0.95</span>)<br><br><br>EPOCH = <span class="hljs-number">100</span><br>patience=<span class="hljs-number">20</span><br>Acc,Loss,ValidLoss=[],[],[]<br><br><span class="hljs-comment"># ============================画图函数============================</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Draw</span>(<span class="hljs-params">X,Y,Z</span>):<br>    plt.plot(X,Y,linestyle=<span class="hljs-string">&#x27;--&#x27;</span>,label=<span class="hljs-string">&#x27;loss&#x27;</span>)<br>    plt.plot(X,Z,label=<span class="hljs-string">&quot;acc&quot;</span>)<br>    plt.legend()<br>    plt.savefig(<span class="hljs-string">f&#x27;./<span class="hljs-subst">&#123;DATA&#125;</span>_res.png&#x27;</span>) <br><br><br><br><span class="hljs-comment"># ===============================定义测试函数=========================</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">epoch,mode</span>):<br>    <span class="hljs-keyword">if</span> mode==<span class="hljs-string">&#x27;test&#x27;</span>:dataloader=test_dataloader<br>    <span class="hljs-keyword">elif</span> mode==<span class="hljs-string">&quot;val&quot;</span>:dataloader=val_dataloader<br><br>    model.<span class="hljs-built_in">eval</span>()<br>    correct,total,Validloss=<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data,label <span class="hljs-keyword">in</span> dataloader:<br>            output = model(data.to(torch.<span class="hljs-built_in">float</span>).to(device))<br>            Validloss+= criterion(output.logits, label.to(device))<br>            _, predicted = torch.<span class="hljs-built_in">max</span>(output.logits, dim=<span class="hljs-number">1</span>) <br>            total += label.size(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 张量之间的比较运算</span><br>            correct += (predicted == label.to(device)).<span class="hljs-built_in">sum</span>().item()<br>        acc = correct / total<br>        ValidLoss.append(Validloss/<span class="hljs-built_in">len</span>(dataloader))<br>        <span class="hljs-keyword">if</span> mode==<span class="hljs-string">&#x27;val&#x27;</span>:<br>            Acc.append(acc)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[%d / %d]: 验证集准确率: %.1f %% &#x27;</span> % (epoch+<span class="hljs-number">1</span>, EPOCH, <span class="hljs-number">100</span> * acc)) <br>        <span class="hljs-keyword">else</span>:<span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试集准确率: %.1f %% &#x27;</span> % (<span class="hljs-number">100</span> * acc))<br>    <br><br><br><span class="hljs-comment"># ===============================训练=========================</span><br>early_stopping = EarlyStopping(patience=patience, verbose=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(EPOCH):<br>    model.train()<br>    EpochLoss=<span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> data,label <span class="hljs-keyword">in</span> train_dataloader:<br><br>        <span class="hljs-comment"># forward [batch_size, n_channels, forecast_horizon]</span><br>        output = model(data.to(torch.<span class="hljs-built_in">float</span>).to(device))<br><br>        <span class="hljs-comment"># backward</span><br>        loss = criterion(output.logits, label.to(device))<br>        optimizer.zero_grad()<br>        loss.backward()<br>        optimizer.step()<br>        <br>        EpochLoss+=loss.item()<br>    Loss.append(EpochLoss/<span class="hljs-built_in">len</span>(train_dataloader))<br>    scheduler.step()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;学习率:<span class="hljs-subst">&#123;scheduler.get_last_lr()[<span class="hljs-number">0</span>]:<span class="hljs-number">.5</span>f&#125;</span>&quot;</span>)<br>    test(_,<span class="hljs-string">&#x27;val&#x27;</span>)<br><br>    early_stopping(ValidLoss[-<span class="hljs-number">1</span>], model)<br>    <span class="hljs-keyword">if</span> early_stopping.early_stop:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Early stopping&quot;</span>)<br>        <span class="hljs-keyword">break</span><br><br>test(<span class="hljs-literal">None</span>,<span class="hljs-string">&#x27;test&#x27;</span>)<br>Draw([_+<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(Loss))],Loss,Acc)<br>torch.save(model,<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;DATA&#125;</span>_ckpt.pt&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="测试结果">2.2 测试结果</h2><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/uwave.png"></div><div class="group-image-wrap"><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/har.png"></div><div class="group-image-wrap"><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/sports.png"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/grabmyo.png"></div><div class="group-image-wrap"><img src="/2024/09/04/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7II/wisdm.png"></div></div></div><h2 id="针对grabmyo的调参">2.3 针对<code>GrabMyo</code>的调参</h2><table><thead><tr class="header"><th style="text-align: center;">数据处理/训练部分</th><th style="text-align: center;">Batchsize</th><th style="text-align: center;">Lr（gamma）</th><th style="text-align: center;">Acc（%）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">concat/cls</td><td style="text-align: center;">512</td><td style="text-align: center;">1e-2（0.95）</td><td style="text-align: center;">11.6</td></tr><tr class="even"><td style="text-align: center;">concat/cls</td><td style="text-align: center;">64</td><td style="text-align: center;">1e-3（0.95）</td><td style="text-align: center;">12.1</td></tr><tr class="odd"><td style="text-align: center;">mean/cls</td><td style="text-align: center;">64</td><td style="text-align: center;">1e-2（0.95）</td><td style="text-align: center;">/</td></tr><tr class="even"><td style="text-align: center;">mean/all</td><td style="text-align: center;">64</td><td style="text-align: center;">1e-2（0.95）</td><td style="text-align: center;">/</td></tr><tr class="odd"><td style="text-align: center;">concat（20%）/all</td><td style="text-align: center;">64</td><td style="text-align: center;">1e-2（0.95）</td><td style="text-align: center;">6.2</td></tr><tr class="even"><td style="text-align: center;">concat（20%）/all</td><td style="text-align: center;">64</td><td style="text-align: center;">1e-3（0.95）</td><td style="text-align: center;"></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>类增量学习</tag>
      
      <tag>微调</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>哈希表</title>
    <link href="/2024/09/04/%E5%93%88%E5%B8%8C%E8%A1%A8/"/>
    <url>/2024/09/04/%E5%93%88%E5%B8%8C%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><p>当需要查询一个元素是否出现过、一个元素是否在集合里、元素出现次数的时候，使用哈希表</p><ol type="1"><li><a href="https://leetcode.cn/problems/4sum-ii/">454. 4Sum II</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
      <tag>哈希表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大模型架构</title>
    <link href="/2024/09/02/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84/"/>
    <url>/2024/09/02/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="auto-encoder-vs-auto-regressive">1、Auto-encoder vs Auto-regressive</h1><p>从预训练模型的角度上来看，两者的模型结构可能是一样的，不同的是预训练的方式</p><ul><li>自编码模型：预训练时可以看到上下文信息，指BERT等；广义来讲是自编码器（AE），包含VAE</li><li>自回归模型：预训练时只能看到上文或者下文，指GPT、ELMO等；广义来讲就是利用过去观测值预测未来值的模型，也包含RNN、LSTM</li></ul><p><strong>参考</strong></p><ol type="1"><li><a href="https://blog.csdn.net/weixin_43301333/article/details/128141716?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522170848482516800222831072%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=170848482516800222831072&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-128141716-null-null.nonecase&amp;utm_term=encoder&amp;spm=1018.2226.3001.4450">Transformer Encoder-Decoer 结构回顾</a></li><li><a href="https://www.cnblogs.com/AudreyXu/p/17197943.html">自回归和自编码有什么区别？</a></li></ol><h1 id="大模型架构">2、大模型架构</h1><p><img src="https://i-blog.csdnimg.cn/blog_migrate/8aba45c21032e2d07fd783070ad8483a.png"></p><ul><li>Encoder-Decoder（T5）</li><li>Decoder Only（GPT）</li><li>Encoder Only（BERT）</li><li>Prefix LM（GLM）</li></ul><p><strong>参考</strong></p><ol type="1"><li><a href="https://www.zhihu.com/question/588325646/answer/2940298964">为什么现在的LLM都是Decoder only的架构？ - 苏剑林的回答 - 知乎</a></li><li><a href="https://www.zhihu.com/question/588325646/answer/3357252612">为什么现在的LLM都是Decoder only的架构？ - Sam多吃青菜的回答 - 知乎</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>编码器</tag>
      
      <tag>解码器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch加速训练MNIST</title>
    <link href="/2024/08/29/Pytorch%E5%8A%A0%E9%80%9F%E8%AE%AD%E7%BB%83/"/>
    <url>/2024/08/29/Pytorch%E5%8A%A0%E9%80%9F%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;  margin-top: 20px;}</style><h1 id="实验过程">0、实验过程</h1><p>为了对比Pytorch中不同方法对于训练速度的提升，采用最基础的<a href="https://blog.csdn.net/qq_45588019/article/details/120935828">MNIST数字识别</a>，基础配置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">64</span><br>learning_rate = <span class="hljs-number">0.01</span><br>momentum = <span class="hljs-number">0.5</span><br>EPOCH = <span class="hljs-number">5</span><br><br>criterion = torch.nn.CrossEntropyLoss()  <br>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)  <br></code></pre></td></tr></table></figure><p>源码是CPU上跑的，改到GPU上作为一个Baseline：</p><div class="center"><table><thead><tr class="header"><th style="text-align: center;">方法</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">CPU</td><td style="text-align: center;">97.9</td><td style="text-align: center;">25.16</td></tr><tr class="even"><td style="text-align: center;">GPU（RTX3080）</td><td style="text-align: center;">98.4</td><td style="text-align: center;">20.40</td></tr></tbody></table></div><h1 id="dataloader">1、Dataloader</h1><p>看到<a href="https://blog.csdn.net/qq_28057379/article/details/115427052">网上</a>有说将<code>num_workers</code>设置成CPU数量一样，但也有的说并非越大越好，可能需要进行实验选择最佳的。在这里测试集准确率参考意义并不大，因为差距很小，并且dataloader不会对准确率造成显著的影响，可能与参数的初始化情况有关</p><div class="center"><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Baseline</td><td style="text-align: center;">98.4</td><td style="text-align: center;">20.40</td></tr><tr class="even"><td style="text-align: center;"><code>num_workers=4</code></td><td style="text-align: center;">98.3</td><td style="text-align: center;">7.54</td></tr><tr class="odd"><td style="text-align: center;"><code>pin_memory=True</code></td><td style="text-align: center;">98.7</td><td style="text-align: center;">21.32</td></tr><tr class="even"><td style="text-align: center;"><code>num_workers=4，pin_memory=True</code></td><td style="text-align: center;">98.4</td><td style="text-align: center;"><strong>6.14</strong></td></tr></tbody></table></div><h1 id="自动混合精度-amp">2、自动混合精度 AMP</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">scaler = GradScaler(enabled=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">for</span> batch_idx, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader, <span class="hljs-number">0</span>):<br>        inputs, target = data<br>        optimizer.zero_grad()<br><br>        <span class="hljs-keyword">with</span> autocast(enabled=<span class="hljs-literal">True</span>, dtype=torch.float16):<br>            outputs = model(inputs.to(device))<br>            loss = criterion(outputs, target.to(device))<br><br>            scaler.scale(loss).backward()<br>            scaler.step(optimizer)<br>            scaler.update()   <br></code></pre></td></tr></table></figure><p>在这个实验中AMP并未提速，反而还慢了，猜想是因为数据集规模太小。不过在之前的比赛中，在对大模型推理时使用混合精度确实有减少推理时间</p><div class="center"><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Baseline</td><td style="text-align: center;">98.4</td><td style="text-align: center;"><strong>20.40</strong></td></tr><tr class="even"><td style="text-align: center;">AMP</td><td style="text-align: center;">98.5</td><td style="text-align: center;">21.83</td></tr></tbody></table></div><h1 id="优化器">3、优化器</h1><p>除了Baseline中设置了动量参数外，其余皆采用默认参数</p><div class="center"><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">测试集准确率（%）</th><th style="text-align: center;">用时（s）</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Baseline</td><td style="text-align: center;">98.4</td><td style="text-align: center;">20.40</td></tr><tr class="even"><td style="text-align: center;">Adam</td><td style="text-align: center;">95.2</td><td style="text-align: center;">20.43</td></tr><tr class="odd"><td style="text-align: center;">AdamW</td><td style="text-align: center;">97.5</td><td style="text-align: center;">20.62</td></tr><tr class="even"><td style="text-align: center;">RMSprop</td><td style="text-align: center;">97.2</td><td style="text-align: center;"><strong>20.04</strong></td></tr><tr class="odd"><td style="text-align: center;">Adagrad</td><td style="text-align: center;"><strong>98.8</strong></td><td style="text-align: center;">20.31</td></tr></tbody></table></div><h1 id="归一化">4、归一化</h1><h1 id="学习率">5、学习率</h1><h1 id="batchsize">6、BatchSize</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数组</title>
    <link href="/2024/08/28/%E6%95%B0%E7%BB%84/"/>
    <url>/2024/08/28/%E6%95%B0%E7%BB%84/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="双指针">1、双指针</h1><ol type="1"><li><p><a href="https://leetcode.cn/problems/squares-of-a-sorted-array/">977. Squares of a Sorted Array</a></p><p><img src="https://code-thinking.cdn.bcebos.com/gifs/977.%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E5%B9%B3%E6%96%B9.gif"></p></li></ol><h1 id="滑动窗口">2、滑动窗口</h1><ol type="1"><li><a href="https://leetcode.cn/problems/minimum-size-subarray-sum/">209. Minimum Size Subarray Sum</a></li></ol><h1 id="模拟行为">3、模拟行为</h1><ol type="1"><li><a href="https://leetcode.cn/problems/spiral-matrix-ii/">59. Spiral Matrix II：模拟顺时针画矩阵的过程</a></li></ol><h1 id="前缀和">4、前缀和</h1><p>重复利用计算过的子数组之和，从而降低区间查询需要累加计算的次数。在涉及计算区间和的问题时非常有用</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>归一化</title>
    <link href="/2024/08/27/%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <url>/2024/08/27/%E5%BD%92%E4%B8%80%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="batchnorm">1、BatchNorm</h1><h1 id="layernorm">2、LayerNorm</h1><p>针对一个样本所有特征计算均值和方差，然后对样本进行归一化</p><p>减少内部协变量偏移（Internal Covariate Shift）： 内部协变量偏移是指在深度神经网络的训练过程中，每一层输入的分布会发生变化，导致网络的训练变得困难。层归一化通过对每一层的输入进行归一化处理，可以减少内部协变量偏移，使得每一层的输入分布更加稳定。 <strong>稳定梯度</strong>： 层归一化有助于保持每一层输出的均值和方差稳定，从而使得梯度的传播更加稳定。这有助于减少梯度消失或梯度爆炸的问题，提高梯度在网络中的流动性，加快训练速度。<sup><a href="#ref1">1</a></sup></p><h1 id="instancenorm">3、InstanceNorm</h1><h1 id="rmsnorm">4、RMSNorm</h1><h1 id="参考">参考</h1><ol type="1"><li><span name="ref1"><a href="https://www.cnblogs.com/shine-lee/p/11989612.html">Batch Normalization详解</a></span></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>归一化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>激活函数</title>
    <link href="/2024/08/26/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <url>/2024/08/26/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="激活函数">1、激活函数</h1><ol type="1"><li><p><code>sigmoid</code>：<span class="math inline">\(\sigma(x)=\frac{1}{1+e^{-x}}\)</span></p><ul><li><p><span class="math inline">\(\rm max\{\sigma&#39;(x)\}=0.25&lt;1\)</span>，容易出现梯度消失</p></li><li><p>输出均值不为0，导致收敛变慢</p><p>​ <a href="https://cloud.tencent.com/developer/article/1829621">非零均值？激活函数也太硬核了</a></p><p>​ <a href="https://liam.page/2018/04/17/zero-centered-active-function/">谈谈激活函数以0为中心 的问题</a></p></li></ul></li><li><p><code>ReLU</code></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>激活函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer</title>
    <link href="/2024/08/24/Transformer/"/>
    <url>/2024/08/24/Transformer/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="结构">1、结构</h1><h1 id="特点">2、特点</h1><ol type="1"><li>支持并行计算，提高推理速度👍</li><li>捕捉长距离依赖关系👍</li><li>计算成本高👎</li><li>对序列长度敏感👎</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面经</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>链表</title>
    <link href="/2024/08/24/%E9%93%BE%E8%A1%A8/"/>
    <url>/2024/08/24/%E9%93%BE%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="链表删除头结点">1、链表删除头结点</h1><ul><li>设置虚拟头结点</li><li>将原来链表的头指针向后移动</li></ul><ol type="1"><li><p><a href="https://leetcode.cn/problems/remove-linked-list-elements/">203. Remove Linked List Elements</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 虚拟头节点法</span><br><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeElements</span>(<span class="hljs-params">self, head: <span class="hljs-type">Optional</span>[ListNode], val: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<br>        <span class="hljs-comment"># 创建虚拟头部节点以简化删除过程</span><br>        dummy_head = ListNode(<span class="hljs-built_in">next</span> = head)<br>        <br>        <span class="hljs-comment"># 遍历列表并删除值为val的节点</span><br>        current = dummy_head<br>        <span class="hljs-keyword">while</span> current.<span class="hljs-built_in">next</span>:<br>            <span class="hljs-keyword">if</span> current.<span class="hljs-built_in">next</span>.val == val:<br>                current.<span class="hljs-built_in">next</span> = current.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">else</span>:<br>                current = current.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-keyword">return</span> dummy_head.<span class="hljs-built_in">next</span><br></code></pre></td></tr></table></figure></li></ol><h1 id="反转链表">2、反转链表</h1><figure><img src="https://code-thinking.cdn.bcebos.com/gifs/206.%E7%BF%BB%E8%BD%AC%E9%93%BE%E8%A1%A8.gif" alt="反转链表"><figcaption aria-hidden="true">反转链表</figcaption></figure><ol type="1"><li><p><a href="https://leetcode.cn/problems/reverse-linked-list/">206. Reverse Linked List</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 双指针法</span><br><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reverseList</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; ListNode:<br>        cur = head   <br>        pre = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">while</span> cur:<br>            temp = cur.<span class="hljs-built_in">next</span> <span class="hljs-comment"># 保存一下 cur的下一个节点，因为接下来要改变cur-&gt;next</span><br>            cur.<span class="hljs-built_in">next</span> = pre <span class="hljs-comment">#反转</span><br>            <span class="hljs-comment">#更新pre、cur指针</span><br>            pre = cur<br>            cur = temp<br>        <span class="hljs-keyword">return</span> pre<br></code></pre></td></tr></table></figure></li></ol><h1 id="快慢指针删除链表倒数第n个节点">3、快慢指针删除链表倒数第n个节点</h1><ol type="1"><li><p><a href="https://leetcode.cn/problems/remove-nth-node-from-end-of-list/">19. Remove Nth Node From End of List</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeNthFromEnd</span>(<span class="hljs-params">self, head: ListNode, n: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:<br>        <span class="hljs-comment"># 创建一个虚拟节点，并将其下一个指针设置为链表的头部</span><br>        dummy_head = ListNode(<span class="hljs-number">0</span>, head)<br>        <br>        <span class="hljs-comment"># 创建两个指针，慢指针和快指针，并将它们初始化为虚拟节点</span><br>        slow = fast = dummy_head<br>        <br>        <span class="hljs-comment"># 快指针比慢指针快 n+1 步</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>):<br>            fast = fast.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-comment"># 移动两个指针，直到快速指针到达链表的末尾</span><br>        <span class="hljs-keyword">while</span> fast:<br>            slow = slow.<span class="hljs-built_in">next</span><br>            fast = fast.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-comment"># 通过更新第 (n-1) 个节点的 next 指针删除第 n 个节点</span><br>        slow.<span class="hljs-built_in">next</span> = slow.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-keyword">return</span> dummy_head.<span class="hljs-built_in">next</span><br></code></pre></td></tr></table></figure></li></ol><h1 id="环形链表">4、环形链表</h1><ol type="1"><li><p><a href="https://leetcode.cn/problems/linked-list-cycle-ii/">142. Linked List Cycle II</a></p><p>这个题目首先要利用快慢指针（步长分别为1、2）求出一个圈的长度是多少，然后利用删除链表中倒数第n个节点中的思想再次使用快慢指针（一个指针领先头指针一个圈的长度）求出入圈节点；下图为另一种做法：上</p><figure><img src="https://code-thinking.cdn.bcebos.com/gifs/142.%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8II%EF%BC%88%E6%B1%82%E5%85%A5%E5%8F%A3%EF%BC%89.gif" alt="另一种做法"><figcaption aria-hidden="true">另一种做法</figcaption></figure></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
      <tag>链表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TSCIL论文笔记·I</title>
    <link href="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/"/>
    <url>/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="阅读论文">〇、阅读论文</h1><ol type="1"><li><a href="https://arxiv.org/abs/1904.07734">增量学习的三种场景及方法：Three scenarios for continual learning</a></li><li><a href="https://arxiv.org/abs/2112.08654">预训练模型图像类增量学习：Learning to Prompt for Continual Learning</a></li><li><a href="https://arxiv.org/abs/2402.12035">时间序列类增量学习的基准：Class-incremental Learning for Time Series:Benchmark and Evaluation</a></li><li><a href="https://arxiv.org/abs/2204.04799">双提示增量学习：DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</a></li><li><a href="https://arxiv.org/abs/2402.03885">时间序列大模型：MOMENT: A Family of Open Time-series Foundation Models</a></li><li><a href="https://arxiv.org/abs/2403.20317">卷积提示：Convolutional Prompting meets Language Models for Continual Learning</a></li></ol><h1 id="一相关工作">一、相关工作</h1><h2 id="增量学习的三种场景及方法">1. 增量学习的三种场景及方法</h2><h3 id="实验方法">1.1 实验方法</h3><ol type="1"><li>正则化（SI、EWC）</li><li>重放（Replay）<ol type="1"><li>用之前模型对当前任务的Input进行标注生成伪数据（LwF）</li><li>生成新数据（DGR、DGR+distill）</li><li>原始数据重现（可能会有隐私或内存问题）</li></ol></li><li>Exemplars（特征提取+最近类均值+重放：iCaRL）</li></ol><h3 id="实验结果">1.2 实验结果</h3><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/MNIST结果.png" alt="实验结果对比：正则化的效果普遍不太行"><figcaption aria-hidden="true">实验结果对比：正则化的效果普遍不太行</figcaption></figure><h2 id="预训练模型图像类增量学习">2. 预训练模型图像类增量学习</h2><h3 id="实验方法-1">2.1 实验方法</h3><ol type="1"><li>设Input为<span class="math inline">\(x\)</span>，通过<span class="math inline">\(q(x)\)</span>进行映射</li><li>计算<span class="math inline">\(q(x)\)</span>与Key的余弦相似度并选择TopN（同一Prompt被选择的次数越多，下次被选择的概率越小）</li><li>将TopN向量，以及进入Embedding层的Input拼接，并放入预训练模型</li></ol><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/L2P.png" alt="L2P"><figcaption aria-hidden="true">L2P</figcaption></figure><h4 id="vit">2.1.1 ViT</h4><p>在细读论文时需要一些ViT的知识，于是找到了这篇博客：<a href="https://blog.csdn.net/MengYa_Dream/article/details/126600748">ViT的cls token作用</a></p><ol type="1"><li>论文中假设输入的2D图像<span class="math inline">\(x \in \mathbb{R}^{H \times W \times C}\)</span>中<span class="math inline">\(H\)</span>，<span class="math inline">\(W\)</span>，<span class="math inline">\(C\)</span>分别代表高度，宽度和通道数</li><li><span class="math inline">\(f=f_r \circ f_e\)</span>是一个复合函数，指的是将输入embedding后送入自注意力层的结果</li><li>ViT中，图像需要切分为若干patch；在这里flattened 2D patches <span class="math inline">\(x_p \in \mathbb{R}^{L \times (S^2 \cdot C)}\)</span>，其中<span class="math inline">\(L\)</span>为patches个数，<span class="math inline">\(S\)</span>为patch size</li><li>为了简化表示，<span class="math inline">\(x_p\)</span>的第一个token被当做是<code>[class token]</code></li><li>embedding layer的作用<span class="math inline">\(f_e:\mathbb{R}^{L \times (S^2 \cdot C)} \rightarrow \mathbb{R}^{L \times D}\)</span>，其中<span class="math inline">\(D\)</span>是嵌入维度</li><li>一个Prompt可以看作是$P_e^{L_p D} <span class="math inline">\(，其中\)</span>L_p$是Prompt的长度</li><li>将Prompt和Input拼接起来可以得到<span class="math inline">\(x_p=[P_e;x_e]\)</span></li><li>送入预训练模型后，即<span class="math inline">\(f=f_r(x_p)\)</span></li></ol><h4 id="prompt-pool">2.1.2 Prompt Pool</h4><p>为什么要采用Pool的原因有三：</p><ol type="1"><li>在推理的时候task identity是不得而知的，因此为每个task设置一个prompt是不可行的</li><li>即使推理时上述信息可以得知，那么task-independent prompt可能阻止了相似任务间的信息共享</li><li>如果只用一个prompt，则会造成灾难性遗忘</li></ol><p>于是定义Prompt集合：<span class="math inline">\(P = \{P_1, P_2, \cdots , P_M \}\)</span>，则ViT的输入为：<span class="math inline">\(x_p = [P_{s_1} ; \cdots ; P_{s_N} ; x_e], 1 ≤ N ≤ M\)</span></p><p>Prompt Pool中其实是Key-Value pair：<span class="math inline">\(\{(k_1, P_1), (k_2, P_2), \cdots , (k_M , P_M )\},k_i \in \mathbb{R}^{D_k}\)</span></p><div class="note note-info">            <p>根据论文来看，M为所有Prompt 的数量，是一个可以定义的参数</p>          </div><h4 id="prompt-query">2.1.3 Prompt Query</h4><ol type="1"><li>Query应仅跟输入实例有关，并且没有可学习的参数；定义Query Function：<span class="math inline">\(q : \mathbb{R}^{H\times W \times C} → \mathbb{R}^{D_k}\)</span></li><li>作者用了ViT作为feature extractor：<span class="math inline">\(q(x) = f (x)[0,:]\)</span>，其实就是<code>[class token]</code>对应的向量<ul><li>同时，作者指出用ConvNet也是可行的</li></ul></li><li>定义相似度计算函数<span class="math inline">\(\gamma : \mathbb{R}^{D_k} \times \mathbb{R}^{D_k} \rightarrow \mathbb{R}\)</span>，作者发现余弦相似度就很好</li><li>问题简化为<span class="math inline">\(K_x = \mathop{argmin}\limits_{\{s_i\}^N_{i=1}\in[1,M ]} \sum\limits_{i=1}^N \gamma (q(x), k_{s_i} )\)</span>，其中<span class="math inline">\(K_x\)</span>是所有Key的一个子集<ul><li>为了让每个Prompt都有机会被引用，训练时改写为<span class="math inline">\(K_x = \mathop{argmin}\limits_{\{s_i\}^N_{i=1}\in[1,M ]} \sum\limits_{i=1}^N \gamma (q(x), k_{s_i} )\cdot h_{s_i}\)</span></li></ul></li></ol><h4 id="loss-function">2.1.4 Loss Function</h4><p><span class="math display">\[\mathop{\rm min} \limits_{P,K,\phi} \mathcal{L}(g_{\phi}(f^{avg}_r (x_p)), y) + \lambda\sum\limits_{K_x}  \gamma (q(x), k_{s_i} ),\quad s.t. K_x在2.1.3中已经得到\]</span></p><h3 id="实验结果-1">2.2 实验结果</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/CIFAR.png"></p><h2 id="时间序列类增量学习的基准">3. 时间序列类增量学习的基准</h2><h3 id="实验方法-2">3.1 实验方法</h3><h4 id="正则化">3.1.1 正则化</h4><p>基于正则化的方法（LwF、MAS、<span class="math inline">\(DT^2W\)</span>）只在UCI-HAR和UWave等任务较少的简单数据集中表现出明显的优势</p><h4 id="归一化bn-vs-ln">3.1.2 归一化：BN vs LN</h4><p>在大多数情况下使用LN的效果要比BN更好</p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/Norm.png" alt="Norm"><figcaption aria-hidden="true">Norm</figcaption></figure><h4 id="rehearsal-baseder-vs-gr">3.1.3 Rehearsal-based：ER vs GR</h4><p>GR在简单数据上较好，甚至好过ER，复杂数据上表现不佳；可能是因为难以生成复杂数据，以及无法控制生成的类别</p><h4 id="meomory-budget在bn和ln上的差异">3.1.4 Meomory budget在BN和LN上的差异</h4><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/memory.png"></p><ul><li>基于ER的方法通常性能会随着Memory budget的增大而提高，到达一定程度会趋于饱和</li><li>在内存足够时，BN在除ASER的方法都与Offline有很大差异，因为随着任务数量增加<span class="math inline">\(B_{M}\)</span>中旧样本比例会减少；LN则接近Offline</li></ul><h4 id="分类器的选择">3.1.5 分类器的选择</h4><p>分类器选择取决于方法与数据集，在ER上的区别并不明显</p><h2 id="双提示增量学习">4. 双提示增量学习</h2><h3 id="实验方法-3">4.1 实验方法</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/dual.png"></p><ol type="1"><li>G-Prompt（唯一，学习任务的一般性）和E-Prompt（每个任务对应一个，学习任务的特殊性）</li><li>利用Prefix-Tuning（效果相比Prompt-Tuning更好，且未改变输入维度）将<span class="math inline">\(p\)</span>分解成<span class="math inline">\(p_{K},p_{V}\in \mathbb R^{L_{p}/2\times D}\)</span>，并且加到多头自注意力层中：<span class="math inline">\(f^{\rm Pre-T}_{\rm prompt}(p,h)={\rm MSA}(h_{Q},[p_{k};h_{K}],[p_{v};h_{V}])\)</span></li><li>训练时，利用<span class="math inline">\(\mathcal L_{\rm match}(x,k_t)=\gamma(q(x),k_t) ,x \in \mathcal D_t\)</span>更新<span class="math inline">\(k_t\)</span>，将G-Prompt和E-Prompt分别加到某些MSA中</li><li>推理时，Input通过Query function映射并选择最相似的E-Prompt</li></ol><h3 id="实验结果-2">4.2 实验结果</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/dual_res.png"></p><h2 id="时间序列大模型">5. 时间序列大模型</h2><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/pile.png"></div><div class="group-image-wrap"><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/moment_radar.png"></div></div></div><h3 id="time-series-pile">5.1 Time-series Pile</h3><h3 id="模型结构">5.2 模型结构</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/moment.png"></p><ol type="1"><li>将时间序列数据分为不重叠的固定长度序列patches（减少内存占用和计算复杂度），映射到D维向量</li><li>在预训练期间，通过使用特殊的掩码嵌入[MASK]来替换 patches嵌入，目标是学习 patches 嵌入</li><li>这些嵌入可以使用轻量级的重建头，而不是与编码器相同大小的解码器，来重建输入时间序列。以便在保持编码器的大部分参数和高级特征不变的同时，对有限数量的可训练参数进行任务特定的微调，从而进行必要的架构修改。</li></ol><h3 id="实验结果-3">5.3 实验结果</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/moment_res1.png"></p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/moment_res2.png" alt="零样本泛化能力"><figcaption aria-hidden="true">零样本泛化能力</figcaption></figure><h2 id="卷积提示">6. 卷积提示</h2><h3 id="实验方法-4">6.1 实验方法</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/卷积.png"></p><ol type="1"><li>GPT-3给出每个任务中类别的visual features，利用BERT进行word embedding</li><li>根据当前任务<span class="math inline">\(t\)</span>和之前任务中类别的visual features计算相似度，取最大相似度的平均值为<span class="math inline">\(sim_{t}\)</span></li><li><span class="math inline">\(J_{max}\)</span>为每个任务的最大Prompt Generator数量，于是$J_{t}=(1-sim_{t}) J_{max} $</li><li>输入图像，<span class="math inline">\(PN_{\phi}\)</span>（唯一）将前一层的<code>[CLS]</code>投影到和Prompt Keys（共M个，唯一） 相同维度并计算余弦相似度得到<span class="math inline">\(s_{i}\)</span></li><li>对于每一层、每一个头有一套Shared Embedding（唯一）和一套Prompt Generator（M个，对应于Prompt Keys；训练时之前任务对应的Generator会被冻结）；对于<span class="math inline">\(G^K_{h,l,m}\)</span>、<span class="math inline">\(G^V_{h,l,m}\)</span>分别与<span class="math inline">\(SE^{K}_{l,h}\)</span>，<span class="math inline">\(SE^{V}_{l,h}\)</span>进行卷积后，和<span class="math inline">\(s_{i}\)</span>相乘求和，将结果concat到下一层：<span class="math inline">\(P_{l+1}^{K}=\sum\limits_{m=1}^{M}s_{l,m}PC^{K}_{l,h,m}\)</span>，<span class="math inline">\(P_{l+1}^{V}=\sum\limits_{m=1}^{M}s_{l,m}PC^{V}_{l,h,m}\)</span></li></ol><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/相似类别.png" alt="根据visual features计算相似度"><figcaption aria-hidden="true">根据visual features计算相似度</figcaption></figure><h3 id="实验结果-4">6.2 实验结果</h3><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/con_cifar100.png"></p><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/con_imagenet.png"></p><h1 id="二l2p">二、L2P</h1><h2 id="踩坑">1. 踩坑</h2><p>在服务器上部署之后，Github上提到没有CIFAR-100的话，在<code>datasets.py</code>更改如下字段：</p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/教程.png" alt="Github上的教程"><figcaption aria-hidden="true">Github上的教程</figcaption></figure><p>但其实不用改的，本来就是<code>True</code></p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/源码1.png" alt="datasets.py"><figcaption aria-hidden="true">datasets.py</figcaption></figure><p>不过在运行的时候会报这个错：</p><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/报错.png" alt="报错说没有cifar100_12p这个路径"><figcaption aria-hidden="true">报错说没有cifar100_12p这个路径</figcaption></figure><p>后来找到了一个脚本文件<code>train_cifar100_l2p.sh</code>执行，但本地并没有<code>local_datasets</code>路径：</p><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/路径.png"></p><p>这个报错上面提到，这个数据集是在<code>torchvision</code>里面<code>cifar.py</code>下载的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">[rank0]:   File <span class="hljs-string">&quot;/home/eee/zym/l2p-pytorch/datasets.py&quot;</span>, line <span class="hljs-number">107</span>, <span class="hljs-keyword">in</span> get_dataset<br>[rank0]:   dataset_train = datasets.CIFAR100(args.data_path, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform_train)<br>[rank0]:   File <span class="hljs-string">&quot;/home/eee/anaconda3/envs/zym/lib/python3.8/site-packages/torchvision/datasets/cifar.py&quot;</span>, line <span class="hljs-number">66</span>, <span class="hljs-keyword">in</span> __init__<br>[rank0]:     <span class="hljs-variable language_">self</span>.download()<br></code></pre></td></tr></table></figure><p>新建了<code>local_datasets</code>后运行脚本文件，还是报错；最后发现脚本路径写的有问题，改成下面即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">--data-path ./local_datasets/ \<br></code></pre></td></tr></table></figure><h2 id="分析">2. 分析</h2><h3 id="代码结构">2.1 代码结构</h3><figure><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/结构.png" alt="代码结构"><figcaption aria-hidden="true">代码结构</figcaption></figure><p>关于为什么要出现<code>original_model</code>和<code>model</code>，是因为作者在这里做了消融实验，微调了model中的部分参数。不过从结果来看，并没有比原始论文的要好。</p><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/冻结.png"></p><h3 id="运行结果">2.2 运行结果</h3><p>注意到Loss出现了负值，是因为采用的多元交叉熵损失函数。</p><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/loss.png"></p><h1 id="三初步设计">三、初步设计</h1><p><img src="/2024/08/17/TSCIL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%C2%B7I/流程.png"></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>类增量学习</tag>
      
      <tag>微调</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BIGAI1-基于Langchain构建用于数据生成Agent</title>
    <link href="/2024/08/06/%E5%9F%BA%E4%BA%8ELangchain%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90Agent/"/>
    <url>/2024/08/06/%E5%9F%BA%E4%BA%8ELangchain%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90Agent/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><p>类似的文章已经在<a href="https://blog.csdn.net/sersama/article/details/139179060?spm=1001.2014.3001.5502">CSDN</a>发布过了，在这里进行简单总结。</p><h1 id="背景">背景</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>实习</tag>
      
      <tag>BIGAI</tag>
      
      <tag>数据生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>百度-基于大模型的广告检索</title>
    <link href="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/"/>
    <url>/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="数据分析以及初赛方法">数据分析以及初赛方法</h1><h2 id="query落地页核心词长度分布">Query、落地页、核心词长度分布</h2><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/query.png" alt="query"><figcaption aria-hidden="true">query</figcaption></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/lp.png" alt="lp"><figcaption aria-hidden="true">lp</figcaption></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/ct.png" alt="ct"><figcaption aria-hidden="true">ct</figcaption></figure><h2 id="广告id分布">广告ID分布</h2><p>在发现Query中的ID远少于广告ID数量后，我想统计ID的分布。最开始采用柱状图，但由于数据量过大，最后绘制出的图像不直观。因此，我向Kimi问到了一种估计分布密度的方法<a href="https://blog.csdn.net/weixin_39910711/article/details/107307509">KDE</a>，这是一种非参数估计方法，相对于参数估计（如：最大似然估计）不需要对数据的分布有先验的认识：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> gaussian_kde<br><br>json file =<span class="hljs-string">&#x27;/home/zym/桌面/FEIJIANG/Doc/Doc_train_ultra.json&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(json file,<span class="hljs-string">&#x27;r&#x27;</span>,encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<span class="hljs-keyword">as</span> file:<br>    js =[json.loads(line)<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> file]<br>    <br>tgt_values=[ _[<span class="hljs-string">&#x27;tgt&#x27;</span>]<span class="hljs-keyword">for</span> <span class="hljs-keyword">in</span> js]<br>tgt_array=np.array(tgt_values,dtype=np.float64)<br><br><span class="hljs-comment"># 将列表转换为NumPy数组</span><br>tgt_array = np.array(tgt_values, dtype=np.float64)<br><br><span class="hljs-comment"># 计算核密度估计，使用高斯核</span><br>kde = gaussian_kde(tgt_array)<br><br><span class="hljs-comment"># 绘制平滑的曲线</span><br>x = np.linspace(np.<span class="hljs-built_in">min</span>(tgt_array), np.<span class="hljs-built_in">max</span>(tgt_array), <span class="hljs-number">1000</span>)<br>y = kde(x)<br></code></pre></td></tr></table></figure><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/ID分布.png" alt="初赛数据的广告ID分布"><figcaption aria-hidden="true">初赛数据的广告ID分布</figcaption></figure><h2 id="训练过程">训练过程</h2><p>在论文中</p><h1 id="baseline">Baseline</h1><p>数据集中有88wDoc，因为论文中提到直接索引效果较好，因此取落地页连续的短语作为Doc；特别地，观察到Doc长度分布不均，因此在生成Doc时设定为长度越长、采样次数越多。最终得到880wDoc，在第一阶段进行索引学习时4000steps已趋于收敛，遂暂停。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/简单Doc.png" alt="简单构建Doc"><figcaption aria-hidden="true">简单构建Doc</figcaption></figure><p>对于Query，按Click进行增强，从500w得到1200w数据。在上一步得到的权重上训练，效果还可以。</p><h1 id="尝试一semantic-docid">尝试一：Semantic DocID</h1><p>官方所给的数据集中ID是没有规律的，不同的广告内容ID可能邻近，相似的广告ID可能很远，因此这对生成式模型而言，像是在做一个“多分类”的任务。在这篇<a href="https://arxiv.org/abs/2309.13335">Model-enhanced Vector Index</a>论文中提到利用Residual Quantization进行层次聚类效果可能会好，于是考虑用模型对广告内容进行Embedding，但因为本地没有显卡用，并且在AIstudio又不能用Pytorch，因此采用<a href="https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers/ERNIE/contents.html">Ernie-3.0-mini</a>。</p><h2 id="q1embedding文件太大">Q1：Embedding文件太大</h2><p>即使采用mini，在对约29000个句子（3%）进行Embedding之后，我的json文件就已经达到了220MB</p><p><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/mini.png"></p><p>文件存储格式如下</p><p><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/json.png"></p><h2 id="q2内存过大">Q2：内存过大</h2><p>因为词袋方法耗时更长，占用内存更大，后来又再次尝试使用Embedding。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;/home/aistudio/embed.json&quot;</span>,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    data=[json.loads(line)<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f]<br></code></pre></td></tr></table></figure><p>居然在读取的时候内存就满了。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/内存.png" alt="内存满了"><figcaption aria-hidden="true">内存满了</figcaption></figure><h1 id="尝试二词袋">尝试二：词袋</h1><p>这里使用Paddle里的Taskflow进行分词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./embed.json&quot;</span>,<span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(res)+<span class="hljs-number">1</span>)):<br>        seg = Taskflow(<span class="hljs-string">&quot;word segmentation&quot;</span>)temp = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x:x!=,<span class="hljs-string">&#x27;,seg(res[str(i)])))</span><br><span class="hljs-string">        # 使用counter计算每个分词出现的次数</span><br><span class="hljs-string">        word count= counter(temp)</span><br><span class="hljs-string">        #按照出现次数进行升序排序</span><br><span class="hljs-string">        sorted word count = dict(sorted(word count.items(), key=lambda item: item[1]))</span><br><span class="hljs-string">        json.dump(&#123;&quot;tgt&quot;:i,&quot;bow&quot;: sorted word count&#125;,f,ensure ascii=False)</span><br></code></pre></td></tr></table></figure><p>最终分词结果文件很大，没有进一步处理。</p><figure><img src="/2024/08/02/%E7%99%BE%E5%BA%A6-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BF%E5%91%8A%E6%A3%80%E7%B4%A2/分词.png" alt="分词结果"><figcaption aria-hidden="true">分词结果</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>百度</tag>
      
      <tag>搜广推</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BIGAI2—微调Qwen-7B生成1-Hop描述</title>
    <link href="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/"/>
    <url>/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h1 id="背景">背景</h1><p>在生成QA时，我们希望生成的数据具有<mark>一定的复杂度</mark>，并且具有<mark>生活化</mark>的特点。</p><p>最基本的一个想法是：当我们需要某个子图（Region Graph）中的物体信息，便直接从已有信息Info中查找，并送入GPT生成QA；然而，基于这种方法所生成的QA十分的简单。我利用GPT-4简单生成了一个Demo，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Base.png" alt="Demo:直接通过知识图谱生成的QA"><figcaption aria-hidden="true">Demo:直接通过知识图谱生成的QA</figcaption></figure><p>很显然这种数据不具有<mark>多样性</mark>，也不满足我们的要求。我们认为在若干定语修饰后的QA可以极大地丰富数据多样性：</p><ul><li>地毯左面紧挨的儿童椅和行李箱旁的双人床哪个更大？</li><li>空调下面的挂画和墙壁右边的衣服哪个数量更多？</li></ul><p>本质上，我们希望对原有数据增加一定的定语——<mark>将程式化的短语转变为流畅丰富的句子</mark>，效果如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Improve.png" alt="1-Hop描述（右）可以丰富QA内容"><figcaption aria-hidden="true">1-Hop描述（右）可以丰富QA内容</figcaption></figure><p>生成大批量数据离不开大模型的帮助。出于对计算资源以及生成效率的考虑，我们没有选择API或是参数量更大的模型，而是在本地部署Qwen-7B，并期待通过微调可以让其生成我们希望的1-Hop描述，如下图框出部分：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/流程.png" alt="生成QA数据集流程"><figcaption aria-hidden="true">生成QA数据集流程</figcaption></figure><h1 id="方法">方法</h1><h2 id="原理浅析">原理浅析</h2><p>除了SFT之外，人们采用更少计算资源进行微调的方法称为PEFT，其中又包含若干种方法。</p><p>我在网上找到的一个时间轴，可以很好地展示发展历程，如下图：</p><figure><img src="https://oscimg.oschina.net/oscnet/9ac87619-bf4f-41d6-9c94-d7a8cb030acb.png" alt="主流微调方法的发展"><figcaption aria-hidden="true">主流微调方法的发展</figcaption></figure><p>因为显卡资源的限制，我们采用P-tuning来进行微调，从而生成1-Hop描述，<a href="https://arxiv.org/abs/2103.10385">论文原文</a>。</p><p>与Prefix-tuning直接给Prompt增加前缀不同，P-tuning在Prompt中随意加入Embedding后的Virtual Token，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/P-tuning.png" alt="P-tuning结构示意图"><figcaption aria-hidden="true">P-tuning结构示意图</figcaption></figure><h2 id="训练数据">训练数据</h2><p>考虑到时间成本以及Token成本，我们决定在Info中选取<mark>部分数据</mark>，将这一部分数据和利用GPT-4生成的1-Hop描述拼接在一起，形成了微调用的训练数据集。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/数据.png" alt="准备微调数据"><figcaption aria-hidden="true">准备微调数据</figcaption></figure><p>通过将人工制作的模板（如下图）与Info中的信息作为Prompt，我们利用GPT-4进行生成；生成的内容需要进一步通过正则表达式的处理，最终成为1-Hop描述。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT1.png" alt="模板1"><figcaption aria-hidden="true">模板1</figcaption></figure><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT2.png" alt="模板2"><figcaption aria-hidden="true">模板2</figcaption></figure><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/GPT3.png" alt="模板3"><figcaption aria-hidden="true">模板3</figcaption></figure><h2 id="训练过程">训练过程</h2><p>Qwen-7B接收到的Prompt由另一套模板以及Info中的信息组成，如下图：</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/Prompt.png" alt="询问功能的模板"><figcaption aria-hidden="true">询问功能的模板</figcaption></figure><p>代码需要放到HGX集群上跑，但是需要排队很久。之前微调的时候loss从14下降到8左右。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/HGX.png" alt="GPU集群"><figcaption aria-hidden="true">GPU集群</figcaption></figure><h1 id="结果">结果</h1><p>整个对Info进行增强生成1-Hop描述的过程很慢，最终也没有将整个map的3000个视角（1000个场景*3个视角）遍历完。</p><figure><img src="/2024/07/31/%E5%BE%AE%E8%B0%83Qwen-7B/结果.png" alt="结果"><figcaption aria-hidden="true">结果</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微调</tag>
      
      <tag>实习</tag>
      
      <tag>BIGAI</tag>
      
      <tag>数据生成</tag>
      
      <tag>大模型</tag>
      
      <tag>P-tuning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
